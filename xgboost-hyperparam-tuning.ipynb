{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75c5565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac1064f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train_ohe_te_fillna.csv')\n",
    "test = pd.read_csv('./data/Test.zip')\n",
    "\n",
    "useful_features = [\n",
    "'MONTANT',\n",
    "'FREQUENCE_RECH',\n",
    "'REVENUE',\n",
    "'ARPU_SEGMENT',\n",
    "'FREQUENCE',\n",
    "'DATA_VOLUME',\n",
    "'ON_NET',\n",
    "'ORANGE',\n",
    "'TIGO',\n",
    "'ZONE1',\n",
    "'ZONE2',\n",
    "# 'MRG',\n",
    "'REGULARITY',\n",
    "# 'TOP_PACK',\n",
    "'FREQ_TOP_PACK',\n",
    "# 'CHURN',\n",
    "'TENURE_CHURN_mean',\n",
    "'REGION_CHURN_mean',\n",
    "'REGION_0',\n",
    "'REGION_1',\n",
    "'REGION_2',\n",
    "'REGION_3',\n",
    "'REGION_4',\n",
    "'REGION_5',\n",
    "'REGION_6',\n",
    "'REGION_7',\n",
    "'REGION_8',\n",
    "'REGION_9',\n",
    "'REGION_10',\n",
    "'REGION_11',\n",
    "'REGION_12',\n",
    "'REGION_13',\n",
    "'TENURE_0',\n",
    "'TENURE_1',\n",
    "'TENURE_2',\n",
    "'TENURE_3',\n",
    "'TENURE_4',\n",
    "'TENURE_5',\n",
    "'TENURE_6',\n",
    "'TENURE_7',\n",
    "]\n",
    "\n",
    "useful_cols = [\n",
    "    'REGION',\n",
    "    'TENURE',\n",
    "    # 'MRG',  # constant\n",
    "    # 'TOP_PACK',  # wtf column\n",
    "    'MONTANT',\n",
    "    'FREQUENCE_RECH',\n",
    "    'REVENUE',\n",
    "    'ARPU_SEGMENT',\n",
    "    'FREQUENCE',\n",
    "    'DATA_VOLUME',\n",
    "    'ON_NET', \n",
    "    'ORANGE',\n",
    "    'TIGO',\n",
    "    'ZONE1',\n",
    "    'ZONE2',\n",
    "    'REGULARITY',\n",
    "    'FREQ_TOP_PACK',\n",
    "    'TENURE_CHURN_mean',\n",
    "    'REGION_CHURN_mean'\n",
    "]\n",
    "\n",
    "cat_cols = [\n",
    "    # 'user_id',\n",
    "    'REGION',\n",
    "    'TENURE',\n",
    "    # 'MRG',  # constant\n",
    "    # 'TOP_PACK',  # wtf column\n",
    "]\n",
    "\n",
    "final_predictions = []\n",
    "scores = []\n",
    "\n",
    "# for cat_col in cat_cols:\n",
    "#     encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "#     unique_values = train[cat_col].unique()\n",
    "\n",
    "#     one_hot_encoded_cols = [f'{cat_col}_{i}' for i in range(len(unique_values))]\n",
    "    \n",
    "#     ohe_df = pd.DataFrame(encoder.fit_transform(train[[cat_col]]).toarray(), columns=one_hot_encoded_cols)\n",
    "#     ohe_df.index = train.index\n",
    "#     train = train.drop(cat_col, axis=1)\n",
    "#     train = pd.concat([train, ohe_df], axis=1)        \n",
    "#     print(f'[{cat_col}] xtrain transformed')\n",
    "\n",
    "# #     ohe_df = pd.DataFrame(encoder.transform(xvalid[[cat_col]]).toarray(), columns=one_hot_encoded_cols)\n",
    "# #     ohe_df.index = xvalid.index\n",
    "# #     xvalid = xvalid.drop(cat_col, axis=1)\n",
    "# #     xvalid = pd.concat([xvalid, ohe_df], axis=1)        \n",
    "# #     print(f'[{cat_col}] xvalid transformed')\n",
    "\n",
    "#     ohe_df = pd.DataFrame(encoder.transform(test[[cat_col]]).toarray(), columns=one_hot_encoded_cols)\n",
    "#     ohe_df.index = test.index\n",
    "#     test = test.drop(cat_col, axis=1)\n",
    "#     test = pd.concat([test, ohe_df], axis=1)\n",
    "#     print(f'[{cat_col}] xtest transformed')\n",
    "    \n",
    "#     useful_cols += one_hot_encoded_cols\n",
    "#     useful_cols.remove(cat_col)\n",
    "    \n",
    "# scaler = StandardScaler()\n",
    "# train[num_cols] = scaler.fit_transform(train[num_cols])\n",
    "# # valid[num_cols] = scaler.transform(xvalid[num_cols])\n",
    "# test[num_cols] = scaler.transform(test[num_cols])\n",
    "\n",
    "def run(trial):\n",
    "    fold = 0\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True)\n",
    "    reg_lambda = trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0)\n",
    "    reg_alpha = trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.1, 1.0)\n",
    "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 1, 7)\n",
    "\n",
    "    xtrain = train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "    ytrain = xtrain['CHURN']\n",
    "    yvalid = xvalid['CHURN']\n",
    "\n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "\n",
    "#     ordinal_encoder = preprocessing.OrdinalEncoder()\n",
    "#     xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n",
    "#     xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        random_state=42,\n",
    "#         tree_method=\"gpu_hist\",\n",
    "#         gpu_id=1,\n",
    "#         predictor=\"gpu_predictor\",\n",
    "        n_estimators=7000,\n",
    "        learning_rate=learning_rate,\n",
    "        reg_lambda=reg_lambda,\n",
    "        reg_alpha=reg_alpha,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        max_depth=max_depth,\n",
    "    )\n",
    "    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n",
    "    preds_valid = model.predict(xvalid)\n",
    "    score = roc_auc_score(yvalid, preds_valid)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfee2ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-11 00:04:46,879]\u001b[0m A new study created in memory with name: no-name-02df9e7f-3459-4c0a-a59d-6c9e445f6f67\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:04:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.62342\n",
      "[1000]\tvalidation_0-logloss:0.27654\n",
      "[2000]\tvalidation_0-logloss:0.27646\n",
      "[3000]\tvalidation_0-logloss:0.27646\n",
      "[3089]\tvalidation_0-logloss:0.27645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-11 00:23:03,419]\u001b[0m Trial 0 finished with value: 0.7759328225331883 and parameters: {'learning_rate': 0.1302145083250643, 'reg_lambda': 0.205739318814619, 'reg_alpha': 8.46452430120468e-06, 'subsample': 0.8302593096897046, 'colsample_bytree': 0.8773860562118906, 'max_depth': 1}. Best is trial 0 with value: 0.7759328225331883.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:23:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.63075\n",
      "[1000]\tvalidation_0-logloss:0.27655\n",
      "[2000]\tvalidation_0-logloss:0.27647\n",
      "[3000]\tvalidation_0-logloss:0.27644\n",
      "[3050]\tvalidation_0-logloss:0.27644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-11 00:41:04,638]\u001b[0m Trial 1 finished with value: 0.7759825613108775 and parameters: {'learning_rate': 0.11632489309638475, 'reg_lambda': 57.4788801616397, 'reg_alpha': 1.0954231148515935e-06, 'subsample': 0.5766475848638271, 'colsample_bytree': 0.7829097547205851, 'max_depth': 1}. Best is trial 1 with value: 0.7759825613108775.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:41:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67687\n",
      "[1000]\tvalidation_0-logloss:0.27334\n",
      "[1824]\tvalidation_0-logloss:0.27327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-11 01:07:57,492]\u001b[0m Trial 2 finished with value: 0.7709533117069707 and parameters: {'learning_rate': 0.025545094373984806, 'reg_lambda': 0.00392506077359536, 'reg_alpha': 1.6437041610700283e-05, 'subsample': 0.23399423770908634, 'colsample_bytree': 0.792689496529303, 'max_depth': 5}. Best is trial 1 with value: 0.7759825613108775.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:08:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68555\n",
      "[1000]\tvalidation_0-logloss:0.27519\n",
      "[2000]\tvalidation_0-logloss:0.27415\n",
      "[3000]\tvalidation_0-logloss:0.27378\n",
      "[4000]\tvalidation_0-logloss:0.27358\n",
      "[5000]\tvalidation_0-logloss:0.27344\n",
      "[6000]\tvalidation_0-logloss:0.27338\n",
      "[6999]\tvalidation_0-logloss:0.27333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-11 02:33:46,064]\u001b[0m Trial 3 finished with value: 0.7703909861130649 and parameters: {'learning_rate': 0.012421749406777961, 'reg_lambda': 0.0012413974450945805, 'reg_alpha': 0.5490274799079778, 'subsample': 0.8110519565653027, 'colsample_bytree': 0.5443559272525499, 'max_depth': 3}. Best is trial 1 with value: 0.7759825613108775.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:33:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68341\n",
      "[1000]\tvalidation_0-logloss:0.27764\n",
      "[2000]\tvalidation_0-logloss:0.27696\n",
      "[3000]\tvalidation_0-logloss:0.27677\n",
      "[4000]\tvalidation_0-logloss:0.27669\n",
      "[5000]\tvalidation_0-logloss:0.27664\n",
      "[6000]\tvalidation_0-logloss:0.27660\n",
      "[6999]\tvalidation_0-logloss:0.27657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-11 03:26:38,728]\u001b[0m Trial 4 finished with value: 0.7757556150917341 and parameters: {'learning_rate': 0.01734890480750199, 'reg_lambda': 1.3785089699350713e-06, 'reg_alpha': 4.79019264298999e-07, 'subsample': 0.8174462123544131, 'colsample_bytree': 0.38838151696518997, 'max_depth': 1}. Best is trial 1 with value: 0.7759825613108775.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:26:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.64177\n",
      "[1000]\tvalidation_0-logloss:0.27425\n",
      "[2000]\tvalidation_0-logloss:0.27388\n",
      "[3000]\tvalidation_0-logloss:0.27378\n",
      "[3197]\tvalidation_0-logloss:0.27378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-11 04:12:31,365]\u001b[0m Trial 5 finished with value: 0.7712250359273162 and parameters: {'learning_rate': 0.08805937615945421, 'reg_lambda': 0.026131397105435338, 'reg_alpha': 0.007075114159118722, 'subsample': 0.4785000181816955, 'colsample_bytree': 0.9736793022789237, 'max_depth': 2}. Best is trial 1 with value: 0.7759825613108775.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:12:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.66356\n",
      "[1000]\tvalidation_0-logloss:0.27486\n",
      "[2000]\tvalidation_0-logloss:0.27405\n",
      "[3000]\tvalidation_0-logloss:0.27376\n",
      "[4000]\tvalidation_0-logloss:0.27363\n",
      "[5000]\tvalidation_0-logloss:0.27352\n",
      "[6000]\tvalidation_0-logloss:0.27347\n",
      "[6999]\tvalidation_0-logloss:0.27342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-11 05:28:47,262]\u001b[0m Trial 6 finished with value: 0.7709215690667116 and parameters: {'learning_rate': 0.05058644883536961, 'reg_lambda': 2.7608482563433188, 'reg_alpha': 13.164424037898252, 'subsample': 0.5402986509616882, 'colsample_bytree': 0.5276011029442162, 'max_depth': 2}. Best is trial 1 with value: 0.7759825613108775.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:28:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67599\n",
      "[1000]\tvalidation_0-logloss:0.27291\n",
      "[2000]\tvalidation_0-logloss:0.27281\n",
      "[2681]\tvalidation_0-logloss:0.27281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-11 06:58:08,124]\u001b[0m Trial 7 finished with value: 0.7682681864484733 and parameters: {'learning_rate': 0.027028495657373555, 'reg_lambda': 4.597515744795734e-08, 'reg_alpha': 52.59713092321981, 'subsample': 0.8839297607586222, 'colsample_bytree': 0.7887698621986795, 'max_depth': 7}. Best is trial 1 with value: 0.7759825613108775.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:58:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.60053\n",
      "[949]\tvalidation_0-logloss:0.27351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-11 07:16:49,250]\u001b[0m Trial 8 finished with value: 0.7705554749034385 and parameters: {'learning_rate': 0.1719677506475023, 'reg_lambda': 47.53387611552142, 'reg_alpha': 0.06230963793919973, 'subsample': 0.5894950140004344, 'colsample_bytree': 0.19358949999759273, 'max_depth': 7}. Best is trial 1 with value: 0.7759825613108775.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:16:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.65579\n",
      "[1000]\tvalidation_0-logloss:0.27463\n",
      "[2000]\tvalidation_0-logloss:0.27405\n",
      "[3000]\tvalidation_0-logloss:0.27383\n",
      "[4000]\tvalidation_0-logloss:0.27372\n",
      "[5000]\tvalidation_0-logloss:0.27367\n",
      "[6000]\tvalidation_0-logloss:0.27364\n",
      "[6999]\tvalidation_0-logloss:0.27360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-11 08:19:12,336]\u001b[0m Trial 9 finished with value: 0.7710875492546604 and parameters: {'learning_rate': 0.07550040904399719, 'reg_lambda': 0.10199510603017523, 'reg_alpha': 3.1032792386572865, 'subsample': 0.6316311785349856, 'colsample_bytree': 0.23103482954276922, 'max_depth': 2}. Best is trial 1 with value: 0.7759825613108775.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(run, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a547c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.11632489309638475,\n",
       " 'reg_lambda': 57.4788801616397,\n",
       " 'reg_alpha': 1.0954231148515935e-06,\n",
       " 'subsample': 0.5766475848638271,\n",
       " 'colsample_bytree': 0.7829097547205851,\n",
       " 'max_depth': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6ef3d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'MONTANT', 'FREQUENCE_RECH', 'REVENUE', 'ARPU_SEGMENT',\n",
       "       'FREQUENCE', 'DATA_VOLUME', 'ON_NET', 'ORANGE', 'TIGO', 'ZONE1',\n",
       "       'ZONE2', 'MRG', 'REGULARITY', 'TOP_PACK', 'FREQ_TOP_PACK', 'CHURN',\n",
       "       'kfold', 'TENURE_CHURN_mean', 'REGION_CHURN_mean', 'REGION_0',\n",
       "       'REGION_1', 'REGION_2', 'REGION_3', 'REGION_4', 'REGION_5', 'REGION_6',\n",
       "       'REGION_7', 'REGION_8', 'REGION_9', 'REGION_10', 'REGION_11',\n",
       "       'REGION_12', 'REGION_13', 'TENURE_0', 'TENURE_1', 'TENURE_2',\n",
       "       'TENURE_3', 'TENURE_4', 'TENURE_5', 'TENURE_6', 'TENURE_7'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
