{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1427547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import optuna\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d0c17c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\pandas\\core\\frame.py:9186: FutureWarning: Passing 'suffixes' which cause duplicate columns {'id_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  return merge(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>REGION</th>\n",
       "      <th>TENURE</th>\n",
       "      <th>MONTANT</th>\n",
       "      <th>FREQUENCE_RECH</th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>ARPU_SEGMENT</th>\n",
       "      <th>FREQUENCE</th>\n",
       "      <th>DATA_VOLUME</th>\n",
       "      <th>ON_NET</th>\n",
       "      <th>...</th>\n",
       "      <th>id_x</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>id_y</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>id_x</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>id_y</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>id</th>\n",
       "      <th>pred_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000bfd7d50f01092811bc0c8d7b0d6fe7c3596</td>\n",
       "      <td>FATICK</td>\n",
       "      <td>K &gt; 24 month</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4251.0</td>\n",
       "      <td>1417.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00000bfd7d50f01092811bc0c8d7b0d6fe7c3596</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>00000bfd7d50f01092811bc0c8d7b0d6fe7c3596</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>00000bfd7d50f01092811bc0c8d7b0d6fe7c3596</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>00000bfd7d50f01092811bc0c8d7b0d6fe7c3596</td>\n",
       "      <td>0.004463</td>\n",
       "      <td>00000bfd7d50f01092811bc0c8d7b0d6fe7c3596</td>\n",
       "      <td>0.008806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000cb4a5d760de88fecb38e2f71b7bec52e834</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I 18-21 month</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>00000cb4a5d760de88fecb38e2f71b7bec52e834</td>\n",
       "      <td>0.869597</td>\n",
       "      <td>00000cb4a5d760de88fecb38e2f71b7bec52e834</td>\n",
       "      <td>0.620179</td>\n",
       "      <td>00000cb4a5d760de88fecb38e2f71b7bec52e834</td>\n",
       "      <td>0.627454</td>\n",
       "      <td>00000cb4a5d760de88fecb38e2f71b7bec52e834</td>\n",
       "      <td>0.607547</td>\n",
       "      <td>00000cb4a5d760de88fecb38e2f71b7bec52e834</td>\n",
       "      <td>0.879773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001654a9d9f96303d9969d0a4a851714a4bb57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K &gt; 24 month</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00001654a9d9f96303d9969d0a4a851714a4bb57</td>\n",
       "      <td>0.282249</td>\n",
       "      <td>00001654a9d9f96303d9969d0a4a851714a4bb57</td>\n",
       "      <td>0.148125</td>\n",
       "      <td>00001654a9d9f96303d9969d0a4a851714a4bb57</td>\n",
       "      <td>0.136944</td>\n",
       "      <td>00001654a9d9f96303d9969d0a4a851714a4bb57</td>\n",
       "      <td>0.132337</td>\n",
       "      <td>00001654a9d9f96303d9969d0a4a851714a4bb57</td>\n",
       "      <td>0.305990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00001dd6fa45f7ba044bd5d84937be464ce78ac2</td>\n",
       "      <td>DAKAR</td>\n",
       "      <td>K &gt; 24 month</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13502.0</td>\n",
       "      <td>4501.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>43804.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00001dd6fa45f7ba044bd5d84937be464ce78ac2</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>00001dd6fa45f7ba044bd5d84937be464ce78ac2</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>00001dd6fa45f7ba044bd5d84937be464ce78ac2</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>00001dd6fa45f7ba044bd5d84937be464ce78ac2</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>00001dd6fa45f7ba044bd5d84937be464ce78ac2</td>\n",
       "      <td>0.005401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000028d9e13a595abe061f9b58f3d76ab907850f</td>\n",
       "      <td>DAKAR</td>\n",
       "      <td>K &gt; 24 month</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>000028d9e13a595abe061f9b58f3d76ab907850f</td>\n",
       "      <td>0.104483</td>\n",
       "      <td>000028d9e13a595abe061f9b58f3d76ab907850f</td>\n",
       "      <td>0.025337</td>\n",
       "      <td>000028d9e13a595abe061f9b58f3d76ab907850f</td>\n",
       "      <td>0.021932</td>\n",
       "      <td>000028d9e13a595abe061f9b58f3d76ab907850f</td>\n",
       "      <td>0.021137</td>\n",
       "      <td>000028d9e13a595abe061f9b58f3d76ab907850f</td>\n",
       "      <td>0.116135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    user_id  REGION         TENURE  MONTANT  \\\n",
       "0  00000bfd7d50f01092811bc0c8d7b0d6fe7c3596  FATICK   K > 24 month   4250.0   \n",
       "1  00000cb4a5d760de88fecb38e2f71b7bec52e834     NaN  I 18-21 month      NaN   \n",
       "2  00001654a9d9f96303d9969d0a4a851714a4bb57     NaN   K > 24 month   3600.0   \n",
       "3  00001dd6fa45f7ba044bd5d84937be464ce78ac2   DAKAR   K > 24 month  13500.0   \n",
       "4  000028d9e13a595abe061f9b58f3d76ab907850f   DAKAR   K > 24 month   1000.0   \n",
       "\n",
       "   FREQUENCE_RECH  REVENUE  ARPU_SEGMENT  FREQUENCE  DATA_VOLUME  ON_NET  ...  \\\n",
       "0            15.0   4251.0        1417.0       17.0          4.0   388.0  ...   \n",
       "1             NaN      NaN           NaN        NaN          NaN     NaN  ...   \n",
       "2             2.0   1020.0         340.0        2.0          NaN    90.0  ...   \n",
       "3            15.0  13502.0        4501.0       18.0      43804.0    41.0  ...   \n",
       "4             1.0    985.0         328.0        1.0          NaN    39.0  ...   \n",
       "\n",
       "                                       id_x    pred_1  \\\n",
       "0  00000bfd7d50f01092811bc0c8d7b0d6fe7c3596  0.000192   \n",
       "1  00000cb4a5d760de88fecb38e2f71b7bec52e834  0.869597   \n",
       "2  00001654a9d9f96303d9969d0a4a851714a4bb57  0.282249   \n",
       "3  00001dd6fa45f7ba044bd5d84937be464ce78ac2  0.000246   \n",
       "4  000028d9e13a595abe061f9b58f3d76ab907850f  0.104483   \n",
       "\n",
       "                                       id_y    pred_2  \\\n",
       "0  00000bfd7d50f01092811bc0c8d7b0d6fe7c3596  0.000734   \n",
       "1  00000cb4a5d760de88fecb38e2f71b7bec52e834  0.620179   \n",
       "2  00001654a9d9f96303d9969d0a4a851714a4bb57  0.148125   \n",
       "3  00001dd6fa45f7ba044bd5d84937be464ce78ac2  0.000508   \n",
       "4  000028d9e13a595abe061f9b58f3d76ab907850f  0.025337   \n",
       "\n",
       "                                       id_x    pred_3  \\\n",
       "0  00000bfd7d50f01092811bc0c8d7b0d6fe7c3596  0.000458   \n",
       "1  00000cb4a5d760de88fecb38e2f71b7bec52e834  0.627454   \n",
       "2  00001654a9d9f96303d9969d0a4a851714a4bb57  0.136944   \n",
       "3  00001dd6fa45f7ba044bd5d84937be464ce78ac2  0.000498   \n",
       "4  000028d9e13a595abe061f9b58f3d76ab907850f  0.021932   \n",
       "\n",
       "                                       id_y    pred_4  \\\n",
       "0  00000bfd7d50f01092811bc0c8d7b0d6fe7c3596  0.004463   \n",
       "1  00000cb4a5d760de88fecb38e2f71b7bec52e834  0.607547   \n",
       "2  00001654a9d9f96303d9969d0a4a851714a4bb57  0.132337   \n",
       "3  00001dd6fa45f7ba044bd5d84937be464ce78ac2  0.004372   \n",
       "4  000028d9e13a595abe061f9b58f3d76ab907850f  0.021137   \n",
       "\n",
       "                                         id    pred_5  \n",
       "0  00000bfd7d50f01092811bc0c8d7b0d6fe7c3596  0.008806  \n",
       "1  00000cb4a5d760de88fecb38e2f71b7bec52e834  0.879773  \n",
       "2  00001654a9d9f96303d9969d0a4a851714a4bb57  0.305990  \n",
       "3  00001dd6fa45f7ba044bd5d84937be464ce78ac2  0.005401  \n",
       "4  000028d9e13a595abe061f9b58f3d76ab907850f  0.116135  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/train_folds.zip\")\n",
    "df_test = pd.read_csv(\"./data/Test.zip\")\n",
    "\n",
    "df1 = pd.read_csv(\"./data/train_pred_1.csv\")\n",
    "df1.columns = [\"id\", \"pred_1\"]\n",
    "df2 = pd.read_csv(\"./data/train_pred_2.csv\")\n",
    "df2.columns = [\"id\", \"pred_2\"]\n",
    "df3 = pd.read_csv(\"./data/train_pred_3.csv\")\n",
    "df3.columns = [\"id\", \"pred_3\"]\n",
    "df4 = pd.read_csv(\"./data/train_pred_4.csv\")\n",
    "df4.columns = [\"id\", \"pred_4\"]\n",
    "df5 = pd.read_csv(\"./data/train_pred_5.csv\")\n",
    "df5.columns = [\"id\", \"pred_5\"]\n",
    "\n",
    "df_test1 = pd.read_csv(\"./data/test_pred_1.csv\")\n",
    "df_test1.columns = [\"id\", \"pred_1\"]\n",
    "df_test2 = pd.read_csv(\"./data/test_pred_2.csv\")\n",
    "df_test2.columns = [\"id\", \"pred_2\"]\n",
    "df_test3 = pd.read_csv(\"./data/test_pred_3.csv\")\n",
    "df_test3.columns = [\"id\", \"pred_3\"]\n",
    "df_test4 = pd.read_csv(\"./data/test_pred_4.csv\")\n",
    "df_test4.columns = [\"id\", \"pred_4\"]\n",
    "df_test5 = pd.read_csv(\"./data/test_pred_5.csv\")\n",
    "df_test5.columns = [\"id\", \"pred_5\"]\n",
    "\n",
    "df = df.merge(df1, left_on=\"user_id\", right_on='id', how=\"left\")\n",
    "df = df.merge(df2, left_on=\"user_id\", right_on='id', how=\"left\")\n",
    "df = df.merge(df3, left_on=\"user_id\", right_on='id', how=\"left\")\n",
    "df = df.merge(df4, left_on=\"user_id\", right_on='id', how=\"left\")\n",
    "df = df.merge(df5, left_on=\"user_id\", right_on='id', how=\"left\")\n",
    "\n",
    "df_test = df_test.merge(df_test1, left_on=\"user_id\", right_on='id', how=\"left\")\n",
    "df_test = df_test.merge(df_test2, left_on=\"user_id\", right_on='id', how=\"left\")\n",
    "df_test = df_test.merge(df_test3, left_on=\"user_id\", right_on='id', how=\"left\")\n",
    "df_test = df_test.merge(df_test4, left_on=\"user_id\", right_on='id', how=\"left\")\n",
    "df_test = df_test.merge(df_test5, left_on=\"user_id\", right_on='id', how=\"left\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f014307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Run:\n",
    "    def __init__(self, model_class, params_builder, fit_params_builder=None):\n",
    "        self._params_builder = params_builder\n",
    "        self._model_class = model_class\n",
    "        self._fit_params_builder = fit_params_builder\n",
    "        \n",
    "    def __call__(self, trial):\n",
    "        fold = 0\n",
    "        useful_cols = ['pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5']\n",
    "\n",
    "        xtrain = df[df['kfold'] != fold].reset_index(drop=True)\n",
    "        xvalid = df[df['kfold'] == fold].reset_index(drop=True)\n",
    "\n",
    "        ytrain = xtrain['CHURN']\n",
    "        yvalid = xvalid['CHURN']\n",
    "\n",
    "        xtrain = xtrain[useful_cols]\n",
    "        xvalid = xvalid[useful_cols]\n",
    "\n",
    "        params = self._params_builder(trial)\n",
    "\n",
    "        model = self._model_class(**params)\n",
    "\n",
    "        fit_params = self._fit_params_builder(xvalid, yvalid) if self._fit_params_builder is not None else {}\n",
    "        model.fit(xtrain, ytrain, **fit_params)\n",
    "        \n",
    "        preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "        score = roc_auc_score(yvalid, preds_valid)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d1ddda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:35:07,191]\u001b[0m A new study created in memory with name: no-name-1f69db01-cf10-42ae-9614-aad5318c7dfb\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:35:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.60521\n",
      "[1000]\tvalidation_0-logloss:0.25193\n",
      "[1339]\tvalidation_0-logloss:0.25196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:35:24,674]\u001b[0m Trial 0 finished with value: 0.9313452479711448 and parameters: {'learning_rate': 0.14186620982968798, 'reg_lambda': 3.55898370381895e-08, 'reg_alpha': 3.0013165259137945e-06, 'subsample': 0.8280581713496301, 'colsample_bytree': 0.1718069127762427, 'max_depth': 3}. Best is trial 0 with value: 0.9313452479711448.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:35:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.59123\n",
      "[339]\tvalidation_0-logloss:0.25371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:35:33,615]\u001b[0m Trial 1 finished with value: 0.9314233350334096 and parameters: {'learning_rate': 0.16485306189596738, 'reg_lambda': 1.758278917718893e-08, 'reg_alpha': 1.6053958496850559e-06, 'subsample': 0.5107660544364498, 'colsample_bytree': 0.6650741481584964, 'max_depth': 7}. Best is trial 1 with value: 0.9314233350334096.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:35:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.64129\n",
      "[1000]\tvalidation_0-logloss:0.25233\n",
      "[1163]\tvalidation_0-logloss:0.25240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:35:58,083]\u001b[0m Trial 2 finished with value: 0.9311870727567833 and parameters: {'learning_rate': 0.08066410804209585, 'reg_lambda': 0.0005030478587637232, 'reg_alpha': 0.8594535298546844, 'subsample': 0.6985015146933687, 'colsample_bytree': 0.2853055220856405, 'max_depth': 6}. Best is trial 1 with value: 0.9314233350334096.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:35:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68573\n",
      "[1000]\tvalidation_0-logloss:0.25153\n",
      "[1756]\tvalidation_0-logloss:0.25153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:36:20,697]\u001b[0m Trial 3 finished with value: 0.9315262100667644 and parameters: {'learning_rate': 0.011083520635458175, 'reg_lambda': 0.0018132184147065685, 'reg_alpha': 5.064528520940246e-05, 'subsample': 0.5017768192129752, 'colsample_bytree': 0.9387918854475346, 'max_depth': 4}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:36:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.64184\n",
      "[858]\tvalidation_0-logloss:0.25212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:36:31,014]\u001b[0m Trial 4 finished with value: 0.9312317525380615 and parameters: {'learning_rate': 0.08008260875929263, 'reg_lambda': 0.007850448629804331, 'reg_alpha': 9.353108043411239e-07, 'subsample': 0.3385514684449773, 'colsample_bytree': 0.13678479081437456, 'max_depth': 3}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:36:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68611\n",
      "[1000]\tvalidation_0-logloss:0.25156\n",
      "[1977]\tvalidation_0-logloss:0.25155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:36:57,376]\u001b[0m Trial 5 finished with value: 0.9315239956202549 and parameters: {'learning_rate': 0.010517724140609913, 'reg_lambda': 48.21147623564954, 'reg_alpha': 0.10335882961658573, 'subsample': 0.6279309057857774, 'colsample_bytree': 0.9288664592279171, 'max_depth': 4}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:36:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.60057\n",
      "[353]\tvalidation_0-logloss:0.25219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:37:06,502]\u001b[0m Trial 6 finished with value: 0.9314773715148985 and parameters: {'learning_rate': 0.14838765015873717, 'reg_lambda': 2.4816715042768913, 'reg_alpha': 2.2509371079446012e-08, 'subsample': 0.7005852536352422, 'colsample_bytree': 0.9954314578608855, 'max_depth': 7}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:37:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.56918\n",
      "[327]\tvalidation_0-logloss:0.25430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:37:14,947]\u001b[0m Trial 7 finished with value: 0.9312793566200093 and parameters: {'learning_rate': 0.20489192237971365, 'reg_lambda': 0.07466098899970175, 'reg_alpha': 0.00036157161387308847, 'subsample': 0.2396117000707823, 'colsample_bytree': 0.8272943863423177, 'max_depth': 7}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:37:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67143\n",
      "[665]\tvalidation_0-logloss:0.25163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:37:27,880]\u001b[0m Trial 8 finished with value: 0.9314814096626701 and parameters: {'learning_rate': 0.032796431558393103, 'reg_lambda': 8.055697523939406, 'reg_alpha': 0.06907093375085971, 'subsample': 0.6114462849668042, 'colsample_bytree': 0.5761363495361246, 'max_depth': 6}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:37:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.64355\n",
      "[522]\tvalidation_0-logloss:0.25172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:37:36,850]\u001b[0m Trial 9 finished with value: 0.9314759598504513 and parameters: {'learning_rate': 0.07657698956305711, 'reg_lambda': 0.007623144490142922, 'reg_alpha': 7.945416049291701e-05, 'subsample': 0.7479030612647701, 'colsample_bytree': 0.45517335216654065, 'max_depth': 5}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:37:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68583\n",
      "[1000]\tvalidation_0-logloss:0.25174\n",
      "[2000]\tvalidation_0-logloss:0.25162\n",
      "[2587]\tvalidation_0-logloss:0.25162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:37:57,471]\u001b[0m Trial 10 finished with value: 0.9314776422547322 and parameters: {'learning_rate': 0.01166777895885094, 'reg_lambda': 1.8585543998380792e-05, 'reg_alpha': 6.692381773407104, 'subsample': 0.9733883314285166, 'colsample_bytree': 0.8005120446547671, 'max_depth': 1}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:37:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68590\n",
      "[1000]\tvalidation_0-logloss:0.25155\n",
      "[1062]\tvalidation_0-logloss:0.25155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:38:12,346]\u001b[0m Trial 11 finished with value: 0.9315149116002862 and parameters: {'learning_rate': 0.010816921345367504, 'reg_lambda': 7.018688056635944e-06, 'reg_alpha': 0.023874188135114712, 'subsample': 0.44388641617786645, 'colsample_bytree': 0.9976296335006828, 'max_depth': 4}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:38:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67803\n",
      "[1000]\tvalidation_0-logloss:0.25157\n",
      "[1131]\tvalidation_0-logloss:0.25157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:38:26,132]\u001b[0m Trial 12 finished with value: 0.9315102417967961 and parameters: {'learning_rate': 0.022774702513919224, 'reg_lambda': 36.053893375969785, 'reg_alpha': 0.003919444106251871, 'subsample': 0.41895908675389315, 'colsample_bytree': 0.8340021075228924, 'max_depth': 3}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:38:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68027\n",
      "[1000]\tvalidation_0-logloss:0.25154\n",
      "[1114]\tvalidation_0-logloss:0.25154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:38:41,588]\u001b[0m Trial 13 finished with value: 0.9315245455142369 and parameters: {'learning_rate': 0.01932543111656227, 'reg_lambda': 0.283987081013669, 'reg_alpha': 0.0001320990527809524, 'subsample': 0.5896311579370536, 'colsample_bytree': 0.732976372282772, 'max_depth': 4}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:38:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68111\n",
      "[1000]\tvalidation_0-logloss:0.25165\n",
      "[2000]\tvalidation_0-logloss:0.25163\n",
      "[2970]\tvalidation_0-logloss:0.25162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:39:04,680]\u001b[0m Trial 14 finished with value: 0.9314617483200296 and parameters: {'learning_rate': 0.019263682682675098, 'reg_lambda': 0.2907848823639397, 'reg_alpha': 6.644921004368946e-05, 'subsample': 0.20586639157501152, 'colsample_bytree': 0.705288301745232, 'max_depth': 1}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:39:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67927\n",
      "[1000]\tvalidation_0-logloss:0.25167\n",
      "[2000]\tvalidation_0-logloss:0.25160\n",
      "[3000]\tvalidation_0-logloss:0.25159\n",
      "[3353]\tvalidation_0-logloss:0.25160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:39:38,789]\u001b[0m Trial 15 finished with value: 0.9314898087891814 and parameters: {'learning_rate': 0.02112463680622347, 'reg_lambda': 0.00010297037173438179, 'reg_alpha': 1.4308633716547765e-05, 'subsample': 0.5277014753310393, 'colsample_bytree': 0.47058463397843114, 'max_depth': 2}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:39:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.66850\n",
      "[525]\tvalidation_0-logloss:0.25161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:39:47,912]\u001b[0m Trial 16 finished with value: 0.9315038178997702 and parameters: {'learning_rate': 0.03728206727845834, 'reg_lambda': 0.2036710575211737, 'reg_alpha': 1.5944722179779208e-08, 'subsample': 0.3363655219629634, 'colsample_bytree': 0.7020387010576554, 'max_depth': 5}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:39:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68271\n",
      "[781]\tvalidation_0-logloss:0.25161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:40:00,552]\u001b[0m Trial 17 finished with value: 0.9315113606360388 and parameters: {'learning_rate': 0.01560204740879758, 'reg_lambda': 5.003435210578672e-07, 'reg_alpha': 0.001591669296140578, 'subsample': 0.10528238346043811, 'colsample_bytree': 0.9061608344732575, 'max_depth': 5}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67294\n",
      "[1000]\tvalidation_0-logloss:0.25159\n",
      "[1026]\tvalidation_0-logloss:0.25159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:40:15,783]\u001b[0m Trial 18 finished with value: 0.9314967247913115 and parameters: {'learning_rate': 0.030516444347116266, 'reg_lambda': 0.00333875032059415, 'reg_alpha': 55.41770196513492, 'subsample': 0.8916467478143042, 'colsample_bytree': 0.6138174819643911, 'max_depth': 4}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68313\n",
      "[1000]\tvalidation_0-logloss:0.25158\n",
      "[2000]\tvalidation_0-logloss:0.25155\n",
      "[2840]\tvalidation_0-logloss:0.25155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:40:43,511]\u001b[0m Trial 19 finished with value: 0.9315176136007615 and parameters: {'learning_rate': 0.015187452538901264, 'reg_lambda': 0.04929051687994666, 'reg_alpha': 2.2049457862867476e-07, 'subsample': 0.5851206399308596, 'colsample_bytree': 0.7525963163623048, 'max_depth': 2}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:40:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.65863\n",
      "[1000]\tvalidation_0-logloss:0.25160\n",
      "[1671]\tvalidation_0-logloss:0.25160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:41:00,325]\u001b[0m Trial 20 finished with value: 0.9314941053110958 and parameters: {'learning_rate': 0.053402567906612665, 'reg_lambda': 0.0002558908089944877, 'reg_alpha': 0.00022826711474953297, 'subsample': 0.46480906571295666, 'colsample_bytree': 0.48891402758652575, 'max_depth': 2}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68602\n",
      "[1000]\tvalidation_0-logloss:0.25156\n",
      "[1781]\tvalidation_0-logloss:0.25155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:41:24,129]\u001b[0m Trial 21 finished with value: 0.9315170067117047 and parameters: {'learning_rate': 0.010671357899718088, 'reg_lambda': 75.77216780551193, 'reg_alpha': 0.030085872109316368, 'subsample': 0.6311002544713166, 'colsample_bytree': 0.9121652539973809, 'max_depth': 4}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68332\n",
      "[880]\tvalidation_0-logloss:0.25153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:41:38,833]\u001b[0m Trial 22 finished with value: 0.931522081566541 and parameters: {'learning_rate': 0.014704040479285965, 'reg_lambda': 2.0039648283500493, 'reg_alpha': 1.3571039630307757, 'subsample': 0.796889965991626, 'colsample_bytree': 0.9411555604140899, 'max_depth': 5}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68644\n",
      "[1000]\tvalidation_0-logloss:0.25158\n",
      "[2000]\tvalidation_0-logloss:0.25155\n",
      "[3000]\tvalidation_0-logloss:0.25154\n",
      "[3012]\tvalidation_0-logloss:0.25154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:42:11,953]\u001b[0m Trial 23 finished with value: 0.9315196187830901 and parameters: {'learning_rate': 0.010030988577353503, 'reg_lambda': 0.9994239122205538, 'reg_alpha': 0.0021753853146023495, 'subsample': 0.6572806748298412, 'colsample_bytree': 0.8574780251257637, 'max_depth': 3}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:42:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67566\n",
      "[1000]\tvalidation_0-logloss:0.25155\n",
      "[1035]\tvalidation_0-logloss:0.25155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:42:26,205]\u001b[0m Trial 24 finished with value: 0.9315152150095344 and parameters: {'learning_rate': 0.026339889979169764, 'reg_lambda': 8.235924814776485, 'reg_alpha': 0.12218502243642194, 'subsample': 0.5349646667490876, 'colsample_bytree': 0.7520296005995359, 'max_depth': 4}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:42:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68385\n",
      "[898]\tvalidation_0-logloss:0.25156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:42:44,316]\u001b[0m Trial 25 finished with value: 0.9315169623822025 and parameters: {'learning_rate': 0.013897601968057898, 'reg_lambda': 0.02032033332978568, 'reg_alpha': 2.0405711738666832e-05, 'subsample': 0.3764849785255411, 'colsample_bytree': 0.90452145598227, 'max_depth': 6}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:42:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68082\n",
      "[1000]\tvalidation_0-logloss:0.25155\n",
      "[1141]\tvalidation_0-logloss:0.25155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:43:00,287]\u001b[0m Trial 26 finished with value: 0.9315192313894565 and parameters: {'learning_rate': 0.018497674920780593, 'reg_lambda': 11.89298617292635, 'reg_alpha': 0.006846909731163768, 'subsample': 0.5469408581226451, 'colsample_bytree': 0.7686754765549385, 'max_depth': 4}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:43:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68447\n",
      "[1000]\tvalidation_0-logloss:0.25156\n",
      "[2000]\tvalidation_0-logloss:0.25154\n",
      "[2095]\tvalidation_0-logloss:0.25154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:43:25,171]\u001b[0m Trial 27 finished with value: 0.931519017362456 and parameters: {'learning_rate': 0.013004611932430223, 'reg_lambda': 0.0020279597823634676, 'reg_alpha': 0.3504538319546383, 'subsample': 0.6937217468602924, 'colsample_bytree': 0.8672018733790055, 'max_depth': 3}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:43:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.66087\n",
      "[878]\tvalidation_0-logloss:0.25228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:43:40,445]\u001b[0m Trial 28 finished with value: 0.931158441648924 and parameters: {'learning_rate': 0.049411981536606, 'reg_lambda': 0.27177074742761176, 'reg_alpha': 1.0037491179212548e-05, 'subsample': 0.7680833556755466, 'colsample_bytree': 0.38752327408622983, 'max_depth': 5}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:43:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68115\n",
      "[1000]\tvalidation_0-logloss:0.25154\n",
      "[1341]\tvalidation_0-logloss:0.25153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:43:58,413]\u001b[0m Trial 29 finished with value: 0.9315261470740653 and parameters: {'learning_rate': 0.01797291245846196, 'reg_lambda': 1.4994585381559856e-07, 'reg_alpha': 0.0005257245332020527, 'subsample': 0.8717978051884362, 'colsample_bytree': 0.9602151670138925, 'max_depth': 4}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:43:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.66607\n",
      "[1000]\tvalidation_0-logloss:0.25156\n",
      "[1062]\tvalidation_0-logloss:0.25156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:44:11,644]\u001b[0m Trial 30 finished with value: 0.9315212043786527 and parameters: {'learning_rate': 0.04117074990968605, 'reg_lambda': 1.0334600366007272e-06, 'reg_alpha': 3.091190307375524e-07, 'subsample': 0.8553455053891994, 'colsample_bytree': 0.647617307196614, 'max_depth': 3}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:44:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68152\n",
      "[1000]\tvalidation_0-logloss:0.25155\n",
      "[1196]\tvalidation_0-logloss:0.25155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:44:28,210]\u001b[0m Trial 31 finished with value: 0.9315163035078521 and parameters: {'learning_rate': 0.017416876479866197, 'reg_lambda': 3.4833068830488235e-05, 'reg_alpha': 0.0007128778385648009, 'subsample': 0.97127469468953, 'colsample_bytree': 0.9487178409894035, 'max_depth': 4}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:44:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67690\n",
      "[861]\tvalidation_0-logloss:0.25154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:44:40,843]\u001b[0m Trial 32 finished with value: 0.9315250491206687 and parameters: {'learning_rate': 0.024429002444400306, 'reg_lambda': 3.0685383268233195e-07, 'reg_alpha': 7.682422761581057e-05, 'subsample': 0.8829487535049547, 'colsample_bytree': 0.9971681019225547, 'max_depth': 4}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:44:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67801\n",
      "[687]\tvalidation_0-logloss:0.25155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:44:53,231]\u001b[0m Trial 33 finished with value: 0.9315242570814104 and parameters: {'learning_rate': 0.022730356751031137, 'reg_lambda': 6.878550799566579e-08, 'reg_alpha': 0.0001323671261817409, 'subsample': 0.8940844538527648, 'colsample_bytree': 0.9979737397596421, 'max_depth': 5}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:44:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67551\n",
      "[937]\tvalidation_0-logloss:0.25156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:45:06,644]\u001b[0m Trial 34 finished with value: 0.9315181281793181 and parameters: {'learning_rate': 0.02654922648616802, 'reg_lambda': 1.1010753921258237e-08, 'reg_alpha': 1.8486869073090787e-06, 'subsample': 0.9231091246646582, 'colsample_bytree': 0.8713196919801455, 'max_depth': 4}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:45:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67602\n",
      "[1000]\tvalidation_0-logloss:0.25155\n",
      "[1345]\tvalidation_0-logloss:0.25155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:45:23,298]\u001b[0m Trial 35 finished with value: 0.9315188681980024 and parameters: {'learning_rate': 0.025813693030655786, 'reg_lambda': 6.621713745813942e-08, 'reg_alpha': 7.043465698303589e-06, 'subsample': 0.8589642200022476, 'colsample_bytree': 0.9554220150698168, 'max_depth': 3}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:45:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68169\n",
      "[1000]\tvalidation_0-logloss:0.25222\n",
      "[2000]\tvalidation_0-logloss:0.25214\n",
      "[3000]\tvalidation_0-logloss:0.25211\n",
      "[4000]\tvalidation_0-logloss:0.25207\n",
      "[5000]\tvalidation_0-logloss:0.25205\n",
      "[6000]\tvalidation_0-logloss:0.25203\n",
      "[6999]\tvalidation_0-logloss:0.25202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:47:10,642]\u001b[0m Trial 36 finished with value: 0.9312934335037568 and parameters: {'learning_rate': 0.017256102113977104, 'reg_lambda': 6.267110053265043e-07, 'reg_alpha': 4.159947322799971e-05, 'subsample': 0.8090846811463277, 'colsample_bytree': 0.21448539548241952, 'max_depth': 5}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:47:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.62411\n",
      "[463]\tvalidation_0-logloss:0.25159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:47:17,485]\u001b[0m Trial 37 finished with value: 0.931506381478596 and parameters: {'learning_rate': 0.10867786885381388, 'reg_lambda': 4.899879758691935e-06, 'reg_alpha': 0.0004552443041171769, 'subsample': 0.743791330114534, 'colsample_bytree': 0.8144369251216672, 'max_depth': 3}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:47:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68440\n",
      "[944]\tvalidation_0-logloss:0.25155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:47:36,900]\u001b[0m Trial 38 finished with value: 0.9315169475998216 and parameters: {'learning_rate': 0.01307276012482084, 'reg_lambda': 1.8429636593755492e-06, 'reg_alpha': 3.3134647658285525e-06, 'subsample': 0.9327882780802975, 'colsample_bytree': 0.7149859050567141, 'max_depth': 6}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:47:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67922\n",
      "[700]\tvalidation_0-logloss:0.25155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:47:47,525]\u001b[0m Trial 39 finished with value: 0.9315178481784463 and parameters: {'learning_rate': 0.020900039275959886, 'reg_lambda': 2.1311898452682798e-07, 'reg_alpha': 0.009883609312085238, 'subsample': 0.48601803836758883, 'colsample_bytree': 0.9687158716996769, 'max_depth': 4}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:47:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.65363\n",
      "[429]\tvalidation_0-logloss:0.25167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:47:56,543]\u001b[0m Trial 40 finished with value: 0.931510487540647 and parameters: {'learning_rate': 0.06048039597460922, 'reg_lambda': 0.0008951813197031803, 'reg_alpha': 5.93784891921589e-07, 'subsample': 0.6978683057921993, 'colsample_bytree': 0.8893207327350433, 'max_depth': 6}. Best is trial 3 with value: 0.9315262100667644.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:47:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67728\n",
      "[665]\tvalidation_0-logloss:0.25154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:48:08,047]\u001b[0m Trial 41 finished with value: 0.9315268411932808 and parameters: {'learning_rate': 0.023835956029813622, 'reg_lambda': 5.130890328573731e-08, 'reg_alpha': 0.00012656316501001615, 'subsample': 0.8939003175888851, 'colsample_bytree': 0.9583514697188609, 'max_depth': 5}. Best is trial 41 with value: 0.9315268411932808.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67130\n",
      "[819]\tvalidation_0-logloss:0.25155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:48:19,703]\u001b[0m Trial 42 finished with value: 0.93152288348424 and parameters: {'learning_rate': 0.03298753101175525, 'reg_lambda': 2.7986015878769235e-08, 'reg_alpha': 0.0006245789326432443, 'subsample': 0.9779965605647953, 'colsample_bytree': 0.94113873948602, 'max_depth': 4}. Best is trial 41 with value: 0.9315268411932808.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67417\n",
      "[590]\tvalidation_0-logloss:0.25155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:48:30,010]\u001b[0m Trial 43 finished with value: 0.9315123021396317 and parameters: {'learning_rate': 0.02858239102405051, 'reg_lambda': 1.648025596936189e-07, 'reg_alpha': 9.5989938709385e-05, 'subsample': 0.8275207163697735, 'colsample_bytree': 0.79391761779873, 'max_depth': 5}. Best is trial 41 with value: 0.9315268411932808.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68493\n",
      "[1000]\tvalidation_0-logloss:0.25155\n",
      "[1981]\tvalidation_0-logloss:0.25154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:48:55,871]\u001b[0m Trial 44 finished with value: 0.9315272373011102 and parameters: {'learning_rate': 0.012279294564643916, 'reg_lambda': 3.5341083287733105e-06, 'reg_alpha': 2.3190508055586554e-05, 'subsample': 0.9271952162018878, 'colsample_bytree': 0.9955235948592415, 'max_depth': 4}. Best is trial 44 with value: 0.9315272373011102.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68479\n",
      "[955]\tvalidation_0-logloss:0.25154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:49:12,371]\u001b[0m Trial 45 finished with value: 0.9315219389465543 and parameters: {'learning_rate': 0.012480171691547024, 'reg_lambda': 1.9255881280874044e-07, 'reg_alpha': 4.676084599935961e-05, 'subsample': 0.9323656164321777, 'colsample_bytree': 0.974954876981782, 'max_depth': 5}. Best is trial 44 with value: 0.9315272373011102.\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:49:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68225\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34608/3730158584.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mxgb_study\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"maximize\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mxgb_study\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_params_buidler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_fit_params_builder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mxgb_study\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    398\u001b[0m             )\n\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m         _optimize(\n\u001b[0m\u001b[0;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             _optimize_sequential(\n\u001b[0m\u001b[0;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34608/3905816519.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_params_builder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxvalid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myvalid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_params_builder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mpreds_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxvalid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1174\u001b[0m         )\n\u001b[0;32m   1175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m         self._Booster = train(\n\u001b[0m\u001b[0;32m   1177\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \"\"\"\n\u001b[1;32m--> 189\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    190\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1499\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1500\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1501\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def xgb_fit_params_builder(xvalid, yvalid):\n",
    "    return {\n",
    "        'early_stopping_rounds': 300, \n",
    "        'eval_set': [(xvalid, yvalid)], \n",
    "        'verbose': 1000\n",
    "    }\n",
    "\n",
    "def xgb_params_buidler(trial):\n",
    "    return {\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True),\n",
    "        'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0),\n",
    "        'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0),\n",
    "        'subsample': trial.suggest_float(\"subsample\", 0.1, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n",
    "        'max_depth': trial.suggest_int(\"max_depth\", 1, 7),\n",
    "        'random_state': 1,\n",
    "        'n_estimators': 7000,\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'gpu_id': 0,\n",
    "        'predictor': \"gpu_predictor\",\n",
    "    }\n",
    "\n",
    "xgb_study = optuna.create_study(direction=\"maximize\")\n",
    "xgb_study.optimize(Run(XGBClassifier, xgb_params_buidler, xgb_fit_params_builder))\n",
    "xgb_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28daa10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.012279294564643916,\n",
       " 'reg_lambda': 3.5341083287733105e-06,\n",
       " 'reg_alpha': 2.3190508055586554e-05,\n",
       " 'subsample': 0.9271952162018878,\n",
       " 'colsample_bytree': 0.9955235948592415,\n",
       " 'max_depth': 4}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e25860c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:51:16,256]\u001b[0m A new study created in memory with name: no-name-8c698ff2-9878-49b2-aba6-445619a23024\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[270]\tvalid_0's binary_logloss: 0.251629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:51:35,798]\u001b[0m Trial 0 finished with value: 0.9314616765954945 and parameters: {'learning_rate': 0.13921524861958795, 'reg_lambda': 2.0757373247040976e-06, 'reg_alpha': 1.526233335372189e-06, 'subsample': 0.6567876461306602, 'colsample_bytree': 0.4673330568614352, 'max_depth': 3}. Best is trial 0 with value: 0.9314616765954945.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.251674\n",
      "[2000]\tvalid_0's binary_logloss: 0.251658\n",
      "[3000]\tvalid_0's binary_logloss: 0.251647\n",
      "[4000]\tvalid_0's binary_logloss: 0.251639\n",
      "[5000]\tvalid_0's binary_logloss: 0.251633\n",
      "[6000]\tvalid_0's binary_logloss: 0.25163\n",
      "[7000]\tvalid_0's binary_logloss: 0.251627\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[7000]\tvalid_0's binary_logloss: 0.251627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:54:42,111]\u001b[0m Trial 1 finished with value: 0.9314595016803876 and parameters: {'learning_rate': 0.10856708304499599, 'reg_lambda': 1.626204828063972e-05, 'reg_alpha': 0.004259197252294888, 'subsample': 0.29050794139033503, 'colsample_bytree': 0.7100857431202984, 'max_depth': 1}. Best is trial 0 with value: 0.9314616765954945.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's binary_logloss: 0.251733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:54:59,569]\u001b[0m Trial 2 finished with value: 0.931404951802227 and parameters: {'learning_rate': 0.2460870354572516, 'reg_lambda': 0.0006396667636616187, 'reg_alpha': 8.994501422027813e-05, 'subsample': 0.3581390851258386, 'colsample_bytree': 0.39082787694281507, 'max_depth': 7}. Best is trial 0 with value: 0.9314616765954945.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.251618\n",
      "Early stopping, best iteration is:\n",
      "[1126]\tvalid_0's binary_logloss: 0.251613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:55:46,891]\u001b[0m Trial 3 finished with value: 0.9314684991405204 and parameters: {'learning_rate': 0.026330085017956285, 'reg_lambda': 1.4984337835780186e-08, 'reg_alpha': 0.0007937002279527174, 'subsample': 0.2308935291170237, 'colsample_bytree': 0.3873789140661211, 'max_depth': 3}. Best is trial 3 with value: 0.9314684991405204.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[252]\tvalid_0's binary_logloss: 0.25192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:56:16,724]\u001b[0m Trial 4 finished with value: 0.9313184236829984 and parameters: {'learning_rate': 0.1537307683788329, 'reg_lambda': 2.867716287812219e-08, 'reg_alpha': 0.00011329234184784254, 'subsample': 0.9431165292566283, 'colsample_bytree': 0.1856112312963314, 'max_depth': 7}. Best is trial 3 with value: 0.9314684991405204.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[300]\tvalid_0's binary_logloss: 0.251538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:56:48,255]\u001b[0m Trial 5 finished with value: 0.9315070527539175 and parameters: {'learning_rate': 0.027447750969975072, 'reg_lambda': 0.3109052004776133, 'reg_alpha': 9.177493455875098, 'subsample': 0.21953817842586992, 'colsample_bytree': 0.6209593285388476, 'max_depth': 7}. Best is trial 5 with value: 0.9315070527539175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.251816\n",
      "[2000]\tvalid_0's binary_logloss: 0.251744\n",
      "[3000]\tvalid_0's binary_logloss: 0.251704\n",
      "[4000]\tvalid_0's binary_logloss: 0.251681\n",
      "[5000]\tvalid_0's binary_logloss: 0.251669\n",
      "[6000]\tvalid_0's binary_logloss: 0.251662\n",
      "[7000]\tvalid_0's binary_logloss: 0.251658\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[6992]\tvalid_0's binary_logloss: 0.251658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 21:59:44,369]\u001b[0m Trial 6 finished with value: 0.9314432287840062 and parameters: {'learning_rate': 0.19658585283551616, 'reg_lambda': 2.382035110599272e-08, 'reg_alpha': 9.16825690420521, 'subsample': 0.19596302545294964, 'colsample_bytree': 0.42116594442305444, 'max_depth': 1}. Best is trial 5 with value: 0.9315070527539175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.251923\n",
      "[2000]\tvalid_0's binary_logloss: 0.251883\n",
      "[3000]\tvalid_0's binary_logloss: 0.251868\n",
      "[4000]\tvalid_0's binary_logloss: 0.25186\n",
      "Early stopping, best iteration is:\n",
      "[4565]\tvalid_0's binary_logloss: 0.251857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:04:34,255]\u001b[0m Trial 7 finished with value: 0.931354178963484 and parameters: {'learning_rate': 0.03900992028636589, 'reg_lambda': 14.04898476382419, 'reg_alpha': 3.2500438846838666e-08, 'subsample': 0.37024267469736205, 'colsample_bytree': 0.23134192136547535, 'max_depth': 6}. Best is trial 5 with value: 0.9315070527539175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[310]\tvalid_0's binary_logloss: 0.251557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:05:04,445]\u001b[0m Trial 8 finished with value: 0.9315020893137794 and parameters: {'learning_rate': 0.024391608957697833, 'reg_lambda': 0.00116942244359967, 'reg_alpha': 1.878877950648792e-06, 'subsample': 0.9896771662205647, 'colsample_bytree': 0.6413621507407997, 'max_depth': 5}. Best is trial 5 with value: 0.9315070527539175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's binary_logloss: 0.251581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:05:19,493]\u001b[0m Trial 9 finished with value: 0.9314922214748262 and parameters: {'learning_rate': 0.13721106309334205, 'reg_lambda': 0.0013508115506651326, 'reg_alpha': 9.671759380906167e-05, 'subsample': 0.2504084267254507, 'colsample_bytree': 0.7553322805103351, 'max_depth': 4}. Best is trial 5 with value: 0.9315070527539175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.251601\n",
      "Early stopping, best iteration is:\n",
      "[1160]\tvalid_0's binary_logloss: 0.251598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:06:28,974]\u001b[0m Trial 10 finished with value: 0.9314755046836588 and parameters: {'learning_rate': 0.011033047058865283, 'reg_lambda': 10.362829430806007, 'reg_alpha': 61.33978880202083, 'subsample': 0.5790591357731385, 'colsample_bytree': 0.9790730203100362, 'max_depth': 5}. Best is trial 5 with value: 0.9315070527539175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[656]\tvalid_0's binary_logloss: 0.251557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:07:15,195]\u001b[0m Trial 11 finished with value: 0.9315013591206157 and parameters: {'learning_rate': 0.018802566675450376, 'reg_lambda': 0.20387168179198467, 'reg_alpha': 0.09765009182875291, 'subsample': 0.9935785088600064, 'colsample_bytree': 0.6593431592312721, 'max_depth': 5}. Best is trial 5 with value: 0.9315070527539175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's binary_logloss: 0.251548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:07:34,574]\u001b[0m Trial 12 finished with value: 0.9315096329673316 and parameters: {'learning_rate': 0.06532551049792827, 'reg_lambda': 0.08429053099127125, 'reg_alpha': 0.7756640422825195, 'subsample': 0.7581700354746058, 'colsample_bytree': 0.861240276021804, 'max_depth': 6}. Best is trial 12 with value: 0.9315096329673316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's binary_logloss: 0.251546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:07:53,355]\u001b[0m Trial 13 finished with value: 0.9315074213079535 and parameters: {'learning_rate': 0.07633038328448143, 'reg_lambda': 0.13815732799194602, 'reg_alpha': 0.868647211174904, 'subsample': 0.7659494825855752, 'colsample_bytree': 0.8972848769105827, 'max_depth': 7}. Best is trial 12 with value: 0.9315096329673316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's binary_logloss: 0.251554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:08:12,252]\u001b[0m Trial 14 finished with value: 0.9315050022366023 and parameters: {'learning_rate': 0.07016588797096639, 'reg_lambda': 0.15722730895601533, 'reg_alpha': 0.16394667744066088, 'subsample': 0.7761351868713506, 'colsample_bytree': 0.9117114787830275, 'max_depth': 6}. Best is trial 12 with value: 0.9315096329673316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's binary_logloss: 0.251552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:08:31,589]\u001b[0m Trial 15 finished with value: 0.9315078292522717 and parameters: {'learning_rate': 0.07020815459303556, 'reg_lambda': 0.018746733996195995, 'reg_alpha': 0.28731499093419277, 'subsample': 0.7992910274157141, 'colsample_bytree': 0.8365000011292951, 'max_depth': 6}. Best is trial 12 with value: 0.9315096329673316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's binary_logloss: 0.251555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:08:52,921]\u001b[0m Trial 16 finished with value: 0.9315051068245925 and parameters: {'learning_rate': 0.05235498213225423, 'reg_lambda': 0.010238946954749932, 'reg_alpha': 0.04434744226416056, 'subsample': 0.7936472980271182, 'colsample_bytree': 0.8087490994020788, 'max_depth': 6}. Best is trial 12 with value: 0.9315096329673316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[401]\tvalid_0's binary_logloss: 0.251558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:09:21,628]\u001b[0m Trial 17 finished with value: 0.9315007613161965 and parameters: {'learning_rate': 0.07666387779782137, 'reg_lambda': 98.76347273657498, 'reg_alpha': 1.7293222375196184, 'subsample': 0.871603916522471, 'colsample_bytree': 0.8312589831906799, 'max_depth': 4}. Best is trial 12 with value: 0.9315096329673316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's binary_logloss: 0.251553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:09:43,547]\u001b[0m Trial 18 finished with value: 0.9315030296354876 and parameters: {'learning_rate': 0.047445071961221656, 'reg_lambda': 6.577074705885464e-05, 'reg_alpha': 0.0038163203289400005, 'subsample': 0.6338522999091442, 'colsample_bytree': 0.5315268347255238, 'max_depth': 6}. Best is trial 12 with value: 0.9315096329673316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[280]\tvalid_0's binary_logloss: 0.251623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:09:59,943]\u001b[0m Trial 19 finished with value: 0.931464010906297 and parameters: {'learning_rate': 0.09102558721687594, 'reg_lambda': 0.01616566109927162, 'reg_alpha': 67.11426461263582, 'subsample': 0.5259489714837167, 'colsample_bytree': 0.9770411541086272, 'max_depth': 3}. Best is trial 12 with value: 0.9315096329673316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's binary_logloss: 0.251556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:10:21,927]\u001b[0m Trial 20 finished with value: 0.93150264853936 and parameters: {'learning_rate': 0.05099574379485251, 'reg_lambda': 1.395492060465124, 'reg_alpha': 0.018050646499240906, 'subsample': 0.5084323712901369, 'colsample_bytree': 0.8501137309039807, 'max_depth': 5}. Best is trial 12 with value: 0.9315096329673316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's binary_logloss: 0.251554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:10:39,998]\u001b[0m Trial 21 finished with value: 0.9315093149873834 and parameters: {'learning_rate': 0.06816497301937198, 'reg_lambda': 0.02054307471269713, 'reg_alpha': 0.7516759720591566, 'subsample': 0.776102902402487, 'colsample_bytree': 0.9190135100910003, 'max_depth': 7}. Best is trial 12 with value: 0.9315096329673316.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's binary_logloss: 0.251547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:11:04,719]\u001b[0m Trial 22 finished with value: 0.9315167216657723 and parameters: {'learning_rate': 0.03742402853979761, 'reg_lambda': 0.01930317931493392, 'reg_alpha': 0.8625153492015838, 'subsample': 0.8577538525785021, 'colsample_bytree': 0.9952021466601776, 'max_depth': 6}. Best is trial 22 with value: 0.9315167216657723.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's binary_logloss: 0.251532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:11:29,679]\u001b[0m Trial 23 finished with value: 0.9315240997672434 and parameters: {'learning_rate': 0.03924735805719372, 'reg_lambda': 2.0139848865528562, 'reg_alpha': 2.380837889033024, 'subsample': 0.6977006896659559, 'colsample_bytree': 0.9408555739613342, 'max_depth': 7}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[230]\tvalid_0's binary_logloss: 0.251546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:11:56,202]\u001b[0m Trial 24 finished with value: 0.9315090988082944 and parameters: {'learning_rate': 0.03771738131720847, 'reg_lambda': 4.132943986332632, 'reg_alpha': 7.072344830099988, 'subsample': 0.6584322887322528, 'colsample_bytree': 0.9958724505188633, 'max_depth': 6}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[485]\tvalid_0's binary_logloss: 0.251528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:12:40,675]\u001b[0m Trial 25 finished with value: 0.9315183350620894 and parameters: {'learning_rate': 0.017727478657865118, 'reg_lambda': 1.2742124546297076, 'reg_alpha': 2.9481194741688648, 'subsample': 0.8775736440483257, 'colsample_bytree': 0.7798979497859347, 'max_depth': 7}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[539]\tvalid_0's binary_logloss: 0.251534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:13:24,541]\u001b[0m Trial 26 finished with value: 0.9315197317853947 and parameters: {'learning_rate': 0.016319712358087525, 'reg_lambda': 1.2217510178408968, 'reg_alpha': 5.995165491427004, 'subsample': 0.10472016822207553, 'colsample_bytree': 0.7698773497516711, 'max_depth': 7}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.251559\n",
      "Early stopping, best iteration is:\n",
      "[767]\tvalid_0's binary_logloss: 0.251549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:14:21,757]\u001b[0m Trial 27 finished with value: 0.9315118672236427 and parameters: {'learning_rate': 0.01214344816007837, 'reg_lambda': 42.57672446110402, 'reg_alpha': 16.901844381345978, 'subsample': 0.10937114666566067, 'colsample_bytree': 0.7429124019227556, 'max_depth': 7}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.251635\n",
      "[2000]\tvalid_0's binary_logloss: 0.251627\n",
      "Early stopping, best iteration is:\n",
      "[1798]\tvalid_0's binary_logloss: 0.251627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:15:25,241]\u001b[0m Trial 28 finished with value: 0.9314586741493034 and parameters: {'learning_rate': 0.014813980305519009, 'reg_lambda': 1.1845068696109247, 'reg_alpha': 72.32801253792015, 'subsample': 0.4726574339370864, 'colsample_bytree': 0.5564953379458037, 'max_depth': 2}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[385]\tvalid_0's binary_logloss: 0.251528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:16:02,087]\u001b[0m Trial 29 finished with value: 0.9315226179129474 and parameters: {'learning_rate': 0.018616527197268664, 'reg_lambda': 0.7604910287106839, 'reg_alpha': 3.006127839175777, 'subsample': 0.684624206008605, 'colsample_bytree': 0.7912024263124939, 'max_depth': 7}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[424]\tvalid_0's binary_logloss: 0.251558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:16:38,085]\u001b[0m Trial 30 finished with value: 0.9315095177423776 and parameters: {'learning_rate': 0.01960775463445263, 'reg_lambda': 4.79100768095361, 'reg_alpha': 0.0173861910884754, 'subsample': 0.6832497204312419, 'colsample_bytree': 0.7039137433403707, 'max_depth': 5}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[516]\tvalid_0's binary_logloss: 0.251534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:17:30,905]\u001b[0m Trial 31 finished with value: 0.9315136612543027 and parameters: {'learning_rate': 0.01492087261805909, 'reg_lambda': 1.5297843955439325, 'reg_alpha': 3.2669141651099745, 'subsample': 0.7015162874427514, 'colsample_bytree': 0.7724173305305564, 'max_depth': 7}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[460]\tvalid_0's binary_logloss: 0.25155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:18:22,074]\u001b[0m Trial 32 finished with value: 0.9315075028932891 and parameters: {'learning_rate': 0.018830959498283138, 'reg_lambda': 0.935453090441927, 'reg_alpha': 21.809506968946323, 'subsample': 0.5922166368088878, 'colsample_bytree': 0.7955651996550579, 'max_depth': 7}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[604]\tvalid_0's binary_logloss: 0.251537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:19:20,639]\u001b[0m Trial 33 finished with value: 0.9315143445601535 and parameters: {'learning_rate': 0.014763804737590095, 'reg_lambda': 24.833516208867575, 'reg_alpha': 2.7731016708114797, 'subsample': 0.420024747007803, 'colsample_bytree': 0.7162179745267803, 'max_depth': 7}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[349]\tvalid_0's binary_logloss: 0.251554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:19:57,172]\u001b[0m Trial 34 finished with value: 0.9315031962812532 and parameters: {'learning_rate': 0.023344897458652637, 'reg_lambda': 1.419641342495033e-06, 'reg_alpha': 0.23674054597290217, 'subsample': 0.8772735516887388, 'colsample_bytree': 0.5772540499057025, 'max_depth': 7}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[583]\tvalid_0's binary_logloss: 0.251549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:20:54,636]\u001b[0m Trial 35 finished with value: 0.931507678870653 and parameters: {'learning_rate': 0.012863033472744251, 'reg_lambda': 0.583339808828128, 'reg_alpha': 0.0008078940386224943, 'subsample': 0.6162296076447051, 'colsample_bytree': 0.6753902799451782, 'max_depth': 7}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's binary_logloss: 0.251545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:21:24,211]\u001b[0m Trial 36 finished with value: 0.9315141201431504 and parameters: {'learning_rate': 0.030015503884599077, 'reg_lambda': 4.5110427031454465, 'reg_alpha': 1.2515915997710233e-05, 'subsample': 0.9229143918081693, 'colsample_bytree': 0.9372709306474258, 'max_depth': 7}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's binary_logloss: 0.251618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:21:52,150]\u001b[0m Trial 37 finished with value: 0.9314748070364292 and parameters: {'learning_rate': 0.0308303071264153, 'reg_lambda': 0.00016981322376649106, 'reg_alpha': 0.004091832248553052, 'subsample': 0.7182214705518231, 'colsample_bytree': 0.31795748529315104, 'max_depth': 6}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.251558\n",
      "Early stopping, best iteration is:\n",
      "[846]\tvalid_0's binary_logloss: 0.251557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:23:05,019]\u001b[0m Trial 38 finished with value: 0.9314998342245427 and parameters: {'learning_rate': 0.010027894905205104, 'reg_lambda': 0.06151669857115697, 'reg_alpha': 21.074528706459613, 'subsample': 0.335594251675993, 'colsample_bytree': 0.5129347479205872, 'max_depth': 7}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.251925\n",
      "[2000]\tvalid_0's binary_logloss: 0.251844\n",
      "[3000]\tvalid_0's binary_logloss: 0.251793\n",
      "[4000]\tvalid_0's binary_logloss: 0.25176\n",
      "[5000]\tvalid_0's binary_logloss: 0.251737\n",
      "[6000]\tvalid_0's binary_logloss: 0.251723\n",
      "[7000]\tvalid_0's binary_logloss: 0.251714\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[6988]\tvalid_0's binary_logloss: 0.251714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:26:51,343]\u001b[0m Trial 39 finished with value: 0.9314098751464803 and parameters: {'learning_rate': 0.022162242297114488, 'reg_lambda': 5.848547194857611e-07, 'reg_alpha': 6.138132861877756e-08, 'subsample': 0.8303635111298532, 'colsample_bytree': 0.11483355132650391, 'max_depth': 2}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[488]\tvalid_0's binary_logloss: 0.251538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:27:33,466]\u001b[0m Trial 40 finished with value: 0.9315099206239947 and parameters: {'learning_rate': 0.016874428788200276, 'reg_lambda': 0.004188790281479188, 'reg_alpha': 4.2619221084141286, 'subsample': 0.10494897661876937, 'colsample_bytree': 0.596590703348381, 'max_depth': 7}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[220]\tvalid_0's binary_logloss: 0.251549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:27:59,043]\u001b[0m Trial 41 finished with value: 0.9315094063276792 and parameters: {'learning_rate': 0.03630948663066423, 'reg_lambda': 0.34459138352601076, 'reg_alpha': 0.6348373435670503, 'subsample': 0.8530091297429249, 'colsample_bytree': 0.8797422472177221, 'max_depth': 6}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[253]\tvalid_0's binary_logloss: 0.251543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:28:26,600]\u001b[0m Trial 42 finished with value: 0.9315186592866229 and parameters: {'learning_rate': 0.03172143928484138, 'reg_lambda': 0.040470307498624486, 'reg_alpha': 1.8119002164651234, 'subsample': 0.9140300541924289, 'colsample_bytree': 0.9527199287045672, 'max_depth': 6}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[304]\tvalid_0's binary_logloss: 0.251542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:28:57,546]\u001b[0m Trial 43 finished with value: 0.9315119999828286 and parameters: {'learning_rate': 0.02911686408338759, 'reg_lambda': 3.26770040395274, 'reg_alpha': 13.99663084864295, 'subsample': 0.9231212816488449, 'colsample_bytree': 0.9509675336686159, 'max_depth': 7}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[320]\tvalid_0's binary_logloss: 0.251534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:29:32,404]\u001b[0m Trial 44 finished with value: 0.931514769368381 and parameters: {'learning_rate': 0.02420385185866237, 'reg_lambda': 10.777104136384924, 'reg_alpha': 2.119404871066056, 'subsample': 0.9515391459436985, 'colsample_bytree': 0.7690049761241897, 'max_depth': 7}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's binary_logloss: 0.251553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:30:04,366]\u001b[0m Trial 45 finished with value: 0.9315064404846388 and parameters: {'learning_rate': 0.021214028379488235, 'reg_lambda': 0.055912262736245597, 'reg_alpha': 0.034859224880037655, 'subsample': 0.7341758328289312, 'colsample_bytree': 0.718230690587965, 'max_depth': 6}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's binary_logloss: 0.25157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:30:29,752]\u001b[0m Trial 46 finished with value: 0.9314998501182481 and parameters: {'learning_rate': 0.04499399278090768, 'reg_lambda': 0.24162447132422873, 'reg_alpha': 35.132762925986874, 'subsample': 0.9012752187148224, 'colsample_bytree': 0.8686017423551371, 'max_depth': 7}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[220]\tvalid_0's binary_logloss: 0.251565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:30:55,555]\u001b[0m Trial 47 finished with value: 0.9315033750810287 and parameters: {'learning_rate': 0.03299455781140437, 'reg_lambda': 0.003097172078999338, 'reg_alpha': 0.117084832201727, 'subsample': 0.8250707372687229, 'colsample_bytree': 0.9390493573968435, 'max_depth': 6}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.251596\n",
      "Early stopping, best iteration is:\n",
      "[1194]\tvalid_0's binary_logloss: 0.251595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:32:04,357]\u001b[0m Trial 48 finished with value: 0.9314808812366564 and parameters: {'learning_rate': 0.016236669719302658, 'reg_lambda': 0.058055036190272205, 'reg_alpha': 7.174381810144883, 'subsample': 0.9598544109190894, 'colsample_bytree': 0.4718766568406161, 'max_depth': 5}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[1000]\tvalid_0's binary_logloss: 0.251579\n",
      "Early stopping, best iteration is:\n",
      "[760]\tvalid_0's binary_logloss: 0.251564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:32:47,060]\u001b[0m Trial 49 finished with value: 0.9314952251381826 and parameters: {'learning_rate': 0.02741185721319138, 'reg_lambda': 0.4090340272588048, 'reg_alpha': 0.24146580217433208, 'subsample': 0.5636273347558117, 'colsample_bytree': 0.7939459481200335, 'max_depth': 4}. Best is trial 23 with value: 0.9315240997672434.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.03924735805719372,\n",
       " 'reg_lambda': 2.0139848865528562,\n",
       " 'reg_alpha': 2.380837889033024,\n",
       " 'subsample': 0.6977006896659559,\n",
       " 'colsample_bytree': 0.9408555739613342,\n",
       " 'max_depth': 7}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lgb_fit_params_builder(xvalid, yvalid):\n",
    "    return {\n",
    "        'early_stopping_rounds': 300, \n",
    "        'eval_set': [(xvalid, yvalid)], \n",
    "        'verbose': 1000\n",
    "    }\n",
    "\n",
    "def lgb_params_buidler(trial):\n",
    "    return {\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True),\n",
    "        'reg_lambda': trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0),\n",
    "        'reg_alpha': trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0),\n",
    "        'subsample': trial.suggest_float(\"subsample\", 0.1, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n",
    "        'max_depth': trial.suggest_int(\"max_depth\", 1, 7),       \n",
    "        'random_state': 42,\n",
    "        'n_estimators': 7000,\n",
    "    }\n",
    "\n",
    "lgb_study = optuna.create_study(direction=\"maximize\")\n",
    "lgb_study.optimize(Run(LGBMClassifier, lgb_params_buidler, lgb_fit_params_builder), n_trials=50, timeout=60*60*2)\n",
    "lgb_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f6f1e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-21 22:32:47,086]\u001b[0m A new study created in memory with name: no-name-885c2d83-2f91-4559-baea-7401713eaca7\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   52.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    1.5s finished\n",
      "\u001b[32m[I 2021-09-21 22:35:09,335]\u001b[0m Trial 0 finished with value: 0.9310460195260559 and parameters: {'rf_max_depth': 15, 'rf_max_features': 'auto', 'rf_class_weight': 'balanced'}. Best is trial 0 with value: 0.9310460195260559.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   48.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-09-21 22:36:00,549]\u001b[0m Trial 1 finished with value: 0.9312344960809072 and parameters: {'rf_max_depth': 4, 'rf_max_features': 'log2', 'rf_class_weight': 'balanced'}. Best is trial 1 with value: 0.9312344960809072.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   56.7s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-09-21 22:36:59,475]\u001b[0m Trial 2 finished with value: 0.9313636209358054 and parameters: {'rf_max_depth': 5, 'rf_max_features': 'log2', 'rf_class_weight': None}. Best is trial 2 with value: 0.9313636209358054.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   37.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-09-21 22:37:38,873]\u001b[0m Trial 3 finished with value: 0.9293592148408867 and parameters: {'rf_max_depth': 3, 'rf_max_features': 'sqrt', 'rf_class_weight': None}. Best is trial 2 with value: 0.9313636209358054.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   27.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-09-21 22:38:08,533]\u001b[0m Trial 4 finished with value: 0.9200015460493423 and parameters: {'rf_max_depth': 2, 'rf_max_features': 'log2', 'rf_class_weight': None}. Best is trial 2 with value: 0.9313636209358054.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   37.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-09-21 22:38:48,608]\u001b[0m Trial 5 finished with value: 0.9298180419130727 and parameters: {'rf_max_depth': 3, 'rf_max_features': 'sqrt', 'rf_class_weight': 'balanced'}. Best is trial 2 with value: 0.9313636209358054.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   50.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-09-21 22:39:41,393]\u001b[0m Trial 6 finished with value: 0.9214211229686629 and parameters: {'rf_max_depth': 2, 'rf_max_features': 'log2', 'rf_class_weight': 'balanced_subsample'}. Best is trial 2 with value: 0.9313636209358054.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    2.6s finished\n",
      "\u001b[32m[I 2021-09-21 22:43:04,235]\u001b[0m Trial 7 finished with value: 0.9288581449458071 and parameters: {'rf_max_depth': 27, 'rf_max_features': 'sqrt', 'rf_class_weight': 'balanced_subsample'}. Best is trial 2 with value: 0.9313636209358054.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2021-09-21 22:44:21,455]\u001b[0m Trial 8 finished with value: 0.9314981561597198 and parameters: {'rf_max_depth': 7, 'rf_max_features': 'log2', 'rf_class_weight': 'balanced'}. Best is trial 8 with value: 0.9314981561597198.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   47.7s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-09-21 22:45:11,339]\u001b[0m Trial 9 finished with value: 0.9311121185184856 and parameters: {'rf_max_depth': 4, 'rf_max_features': 'sqrt', 'rf_class_weight': None}. Best is trial 8 with value: 0.9314981561597198.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "\u001b[32m[I 2021-09-21 22:46:54,767]\u001b[0m Trial 10 finished with value: 0.9315042639819253 and parameters: {'rf_max_depth': 10, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   45.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "\u001b[32m[I 2021-09-21 22:48:54,292]\u001b[0m Trial 11 finished with value: 0.9314537668751566 and parameters: {'rf_max_depth': 12, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   36.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2021-09-21 22:50:30,990]\u001b[0m Trial 12 finished with value: 0.9314952617589731 and parameters: {'rf_max_depth': 9, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2021-09-21 22:51:49,571]\u001b[0m Trial 13 finished with value: 0.9314914418365392 and parameters: {'rf_max_depth': 7, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    1.9s finished\n",
      "\u001b[32m[I 2021-09-21 22:54:42,763]\u001b[0m Trial 14 finished with value: 0.9305950448439717 and parameters: {'rf_max_depth': 21, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2021-09-21 22:56:17,546]\u001b[0m Trial 15 finished with value: 0.9314952617589731 and parameters: {'rf_max_depth': 9, 'rf_max_features': 'log2', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   53.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    1.3s finished\n",
      "\u001b[32m[I 2021-09-21 22:58:38,733]\u001b[0m Trial 16 finished with value: 0.9312681275142962 and parameters: {'rf_max_depth': 15, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2021-09-21 22:59:47,824]\u001b[0m Trial 17 finished with value: 0.931475719345702 and parameters: {'rf_max_depth': 6, 'rf_max_features': 'log2', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   38.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "\u001b[32m[I 2021-09-21 23:01:30,294]\u001b[0m Trial 18 finished with value: 0.9315042639819253 and parameters: {'rf_max_depth': 10, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   42.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    1.0s finished\n",
      "\u001b[32m[I 2021-09-21 23:03:22,269]\u001b[0m Trial 19 finished with value: 0.9314566677145296 and parameters: {'rf_max_depth': 11, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   57.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    1.5s finished\n",
      "\u001b[32m[I 2021-09-21 23:05:57,009]\u001b[0m Trial 20 finished with value: 0.9310878794535338 and parameters: {'rf_max_depth': 17, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2021-09-21 23:07:16,401]\u001b[0m Trial 21 finished with value: 0.9314914418365392 and parameters: {'rf_max_depth': 7, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2021-09-21 23:08:50,696]\u001b[0m Trial 22 finished with value: 0.9314952617589731 and parameters: {'rf_max_depth': 9, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   44.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    1.0s finished\n",
      "\u001b[32m[I 2021-09-21 23:10:50,425]\u001b[0m Trial 23 finished with value: 0.9314537668751566 and parameters: {'rf_max_depth': 12, 'rf_max_features': 'log2', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-09-21 23:11:58,646]\u001b[0m Trial 24 finished with value: 0.931475719345702 and parameters: {'rf_max_depth': 6, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.5min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    3.5s finished\n",
      "\u001b[32m[I 2021-09-21 23:15:31,893]\u001b[0m Trial 25 finished with value: 0.9292255597507528 and parameters: {'rf_max_depth': 31, 'rf_max_features': 'log2', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "\u001b[32m[I 2021-09-21 23:18:20,725]\u001b[0m Trial 26 finished with value: 0.9307105055928201 and parameters: {'rf_max_depth': 20, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   38.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "\u001b[32m[I 2021-09-21 23:20:03,337]\u001b[0m Trial 27 finished with value: 0.9315042639819253 and parameters: {'rf_max_depth': 10, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "\u001b[32m[I 2021-09-21 23:21:48,105]\u001b[0m Trial 28 finished with value: 0.9315042639819253 and parameters: {'rf_max_depth': 10, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   57.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    1.4s finished\n",
      "\u001b[32m[I 2021-09-21 23:24:20,663]\u001b[0m Trial 29 finished with value: 0.9311931796969851 and parameters: {'rf_max_depth': 16, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   48.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "\u001b[32m[I 2021-09-21 23:26:28,389]\u001b[0m Trial 30 finished with value: 0.9313744407036343 and parameters: {'rf_max_depth': 13, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2021-09-21 23:27:54,797]\u001b[0m Trial 31 finished with value: 0.9315039455962556 and parameters: {'rf_max_depth': 8, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "\u001b[32m[I 2021-09-21 23:29:38,241]\u001b[0m Trial 32 finished with value: 0.9315042639819253 and parameters: {'rf_max_depth': 10, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   22.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   57.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2021-09-21 23:30:37,802]\u001b[0m Trial 33 finished with value: 0.9313636209358054 and parameters: {'rf_max_depth': 5, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   52.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    1.2s finished\n",
      "\u001b[32m[I 2021-09-21 23:32:55,983]\u001b[0m Trial 34 finished with value: 0.9312889111359934 and parameters: {'rf_max_depth': 14, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "\u001b[32m[I 2021-09-21 23:34:39,433]\u001b[0m Trial 35 finished with value: 0.9315042639819253 and parameters: {'rf_max_depth': 10, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    1.7s finished\n",
      "\u001b[32m[I 2021-09-21 23:37:30,115]\u001b[0m Trial 36 finished with value: 0.9307105055928201 and parameters: {'rf_max_depth': 20, 'rf_max_features': 'sqrt', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   58.8s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-09-21 23:38:31,054]\u001b[0m Trial 37 finished with value: 0.9313636209358054 and parameters: {'rf_max_depth': 5, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   32.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2021-09-21 23:39:57,945]\u001b[0m Trial 38 finished with value: 0.9315039455962556 and parameters: {'rf_max_depth': 8, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.6s finished\n",
      "\u001b[32m[I 2021-09-21 23:41:06,528]\u001b[0m Trial 39 finished with value: 0.931475719345702 and parameters: {'rf_max_depth': 6, 'rf_max_features': 'sqrt', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "\u001b[32m[I 2021-09-21 23:42:58,517]\u001b[0m Trial 40 finished with value: 0.9314566677145296 and parameters: {'rf_max_depth': 11, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "\u001b[32m[I 2021-09-21 23:44:41,639]\u001b[0m Trial 41 finished with value: 0.9315042639819253 and parameters: {'rf_max_depth': 10, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2021-09-21 23:46:09,287]\u001b[0m Trial 42 finished with value: 0.9315039455962556 and parameters: {'rf_max_depth': 8, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   48.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "\u001b[32m[I 2021-09-21 23:48:17,664]\u001b[0m Trial 43 finished with value: 0.9313744407036343 and parameters: {'rf_max_depth': 13, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "\u001b[32m[I 2021-09-21 23:50:03,410]\u001b[0m Trial 44 finished with value: 0.9315042639819253 and parameters: {'rf_max_depth': 10, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   58.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    1.5s finished\n",
      "\u001b[32m[I 2021-09-21 23:52:37,201]\u001b[0m Trial 45 finished with value: 0.9310878794535338 and parameters: {'rf_max_depth': 17, 'rf_max_features': 'sqrt', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   47.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "\u001b[32m[I 2021-09-21 23:53:26,445]\u001b[0m Trial 46 finished with value: 0.9311121185184856 and parameters: {'rf_max_depth': 4, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   42.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    1.0s finished\n",
      "\u001b[32m[I 2021-09-21 23:55:19,617]\u001b[0m Trial 47 finished with value: 0.9314566677145296 and parameters: {'rf_max_depth': 11, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.7s finished\n",
      "\u001b[32m[I 2021-09-21 23:56:45,590]\u001b[0m Trial 48 finished with value: 0.9315039455962556 and parameters: {'rf_max_depth': 8, 'rf_max_features': 'auto', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   35.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "\u001b[32m[I 2021-09-21 23:58:21,106]\u001b[0m Trial 49 finished with value: 0.9314952617589731 and parameters: {'rf_max_depth': 9, 'rf_max_features': 'sqrt', 'rf_class_weight': None}. Best is trial 10 with value: 0.9315042639819253.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rf_max_depth': 10, 'rf_max_features': 'auto', 'rf_class_weight': None}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rf_params_buidler(trial):\n",
    "    return {\n",
    "        'max_depth': trial.suggest_int('rf_max_depth', 2, 32, log=True),\n",
    "        'max_features': trial.suggest_categorical('rf_max_features', [\"auto\", \"sqrt\", \"log2\"]),\n",
    "        'class_weight': trial.suggest_categorical('rf_class_weight', ['balanced', 'balanced_subsample', None]),\n",
    "        'n_estimators': 100,\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42,\n",
    "        'verbose': 1,\n",
    "    }\n",
    "\n",
    "rf_study = optuna.create_study(direction=\"maximize\")\n",
    "rf_study.optimize(Run(RandomForestClassifier, rf_params_buidler), n_trials=50, timeout=60*60*2)\n",
    "rf_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d347566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-22 09:01:48,660]\u001b[0m A new study created in memory with name: no-name-0b3a7837-eeb8-40b2-8f7a-de634477dba0\u001b[0m\n",
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\optuna\\progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8011a10f1504e4e9fec894f52a222c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6796327\ttest: 0.6796633\tbest: 0.6796633 (0)\ttotal: 330ms\tremaining: 5m 29s\n",
      "999:\tlearn: 0.2620423\ttest: 0.2623776\tbest: 0.2623776 (999)\ttotal: 1m 56s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2623776244\n",
      "bestIteration = 999\n",
      "\n",
      "\u001b[32m[I 2021-09-22 09:03:47,432]\u001b[0m Trial 0 finished with value: 0.9290530728103573 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.016969110504932546, 'depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.1427344213620881}. Best is trial 0 with value: 0.9290530728103573.\u001b[0m\n",
      "0:\tlearn: 0.6796327\ttest: 0.6796633\tbest: 0.6796633 (0)\ttotal: 352ms\tremaining: 5m 51s\n",
      "999:\tlearn: 0.2532269\ttest: 0.2535496\tbest: 0.2535496 (999)\ttotal: 5m 17s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2535496199\n",
      "bestIteration = 999\n",
      "\n",
      "\u001b[32m[I 2021-09-22 09:09:08,798]\u001b[0m Trial 1 finished with value: 0.9309186157601178 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.03196534993902082, 'depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6203739071702407}. Best is trial 1 with value: 0.9309186157601178.\u001b[0m\n",
      "Learning rate set to 0.199658\n",
      "0:\tlearn: 0.6122780\ttest: 0.6124818\tbest: 0.6124818 (0)\ttotal: 132ms\tremaining: 2m 11s\n",
      "999:\tlearn: 0.2517718\ttest: 0.2523637\tbest: 0.2523637 (996)\ttotal: 1m 53s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2523636554\n",
      "bestIteration = 996\n",
      "\n",
      "Shrink model to first 997 iterations.\n",
      "\u001b[32m[I 2021-09-22 09:11:05,058]\u001b[0m Trial 2 finished with value: 0.9311040685772107 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.0609114696910684, 'depth': 7, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 1.5222840623258438}. Best is trial 2 with value: 0.9311040685772107.\u001b[0m\n",
      "Learning rate set to 0.199658\n",
      "0:\tlearn: 0.5219112\ttest: 0.5215581\tbest: 0.5215581 (0)\ttotal: 410ms\tremaining: 6m 49s\n",
      "999:\tlearn: 0.2516902\ttest: 0.2521294\tbest: 0.2521294 (999)\ttotal: 5m 2s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2521294419\n",
      "bestIteration = 999\n",
      "\n",
      "\u001b[32m[I 2021-09-22 09:16:10,983]\u001b[0m Trial 3 finished with value: 0.9312170459037229 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.052545615278841704, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 3 with value: 0.9312170459037229.\u001b[0m\n",
      "0:\tlearn: 0.6632323\ttest: 0.6631573\tbest: 0.6631573 (0)\ttotal: 391ms\tremaining: 6m 30s\n",
      "999:\tlearn: 0.2522228\ttest: 0.2526039\tbest: 0.2526039 (998)\ttotal: 5m 12s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2526039195\n",
      "bestIteration = 998\n",
      "\n",
      "Shrink model to first 999 iterations.\n",
      "\u001b[32m[I 2021-09-22 09:21:27,241]\u001b[0m Trial 4 finished with value: 0.9311243303173611 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.04946347067789804, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 1.0664876573394022}. Best is trial 3 with value: 0.9312170459037229.\u001b[0m\n",
      "Learning rate set to 0.199658\n",
      "0:\tlearn: 0.6122780\ttest: 0.6124818\tbest: 0.6124818 (0)\ttotal: 141ms\tremaining: 2m 21s\n",
      "999:\tlearn: 0.2519086\ttest: 0.2522726\tbest: 0.2522726 (999)\ttotal: 1m 52s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2522725796\n",
      "bestIteration = 999\n",
      "\n",
      "\u001b[32m[I 2021-09-22 09:23:22,449]\u001b[0m Trial 5 finished with value: 0.9311548210769502 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.0521598337672387, 'depth': 5, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.15113960563099946}. Best is trial 3 with value: 0.9312170459037229.\u001b[0m\n",
      "Learning rate set to 0.199658\n",
      "0:\tlearn: 0.6122780\ttest: 0.6124818\tbest: 0.6124818 (0)\ttotal: 369ms\tremaining: 6m 8s\n",
      "999:\tlearn: 0.2516158\ttest: 0.2521355\tbest: 0.2521355 (999)\ttotal: 5m 10s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2521355173\n",
      "bestIteration = 999\n",
      "\n",
      "\u001b[32m[I 2021-09-22 09:28:36,060]\u001b[0m Trial 6 finished with value: 0.9311904774319089 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.07122109833264798, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.3328119368682183}. Best is trial 3 with value: 0.9312170459037229.\u001b[0m\n",
      "0:\tlearn: 0.6538131\ttest: 0.6537800\tbest: 0.6537800 (0)\ttotal: 596ms\tremaining: 9m 55s\n",
      "999:\tlearn: 0.2515948\ttest: 0.2520486\tbest: 0.2520486 (999)\ttotal: 6m 30s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2520486113\n",
      "bestIteration = 999\n",
      "\n",
      "\u001b[32m[I 2021-09-22 09:35:10,594]\u001b[0m Trial 7 finished with value: 0.9313026071352943 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.08879578649380314, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 7 with value: 0.9313026071352943.\u001b[0m\n",
      "0:\tlearn: 0.6796327\ttest: 0.6796633\tbest: 0.6796633 (0)\ttotal: 144ms\tremaining: 2m 23s\n",
      "999:\tlearn: 0.2584822\ttest: 0.2587553\tbest: 0.2587553 (999)\ttotal: 2m 13s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.258755312\n",
      "bestIteration = 999\n",
      "\n",
      "\u001b[32m[I 2021-09-22 09:37:26,423]\u001b[0m Trial 8 finished with value: 0.9301516512300337 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.019869470550110582, 'depth': 3, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8156806340975964}. Best is trial 7 with value: 0.9313026071352943.\u001b[0m\n",
      "0:\tlearn: 0.6796327\ttest: 0.6796633\tbest: 0.6796633 (0)\ttotal: 131ms\tremaining: 2m 10s\n",
      "999:\tlearn: 0.2598004\ttest: 0.2600008\tbest: 0.2600008 (999)\ttotal: 2m 12s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2600008085\n",
      "bestIteration = 999\n",
      "\n",
      "\u001b[32m[I 2021-09-22 09:39:41,445]\u001b[0m Trial 9 finished with value: 0.9294761497705991 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.04025268342764061, 'depth': 6, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 7.806954815793859}. Best is trial 7 with value: 0.9313026071352943.\u001b[0m\n",
      "0:\tlearn: 0.6632323\ttest: 0.6631573\tbest: 0.6631573 (0)\ttotal: 444ms\tremaining: 7m 23s\n",
      "999:\tlearn: 0.2522502\ttest: 0.2526195\tbest: 0.2526195 (999)\ttotal: 6m 23s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2526195108\n",
      "bestIteration = 999\n",
      "\n",
      "\u001b[32m[I 2021-09-22 09:46:08,637]\u001b[0m Trial 10 finished with value: 0.9310671578014118 and parameters: {'objective': 'CrossEntropy', 'colsample_bylevel': 0.0969001911125272, 'depth': 1, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 7 with value: 0.9313026071352943.\u001b[0m\n",
      "Learning rate set to 0.199658\n",
      "0:\tlearn: 0.4775720\ttest: 0.4774163\tbest: 0.4774163 (0)\ttotal: 556ms\tremaining: 9m 15s\n",
      "999:\tlearn: 0.2513576\ttest: 0.2518762\tbest: 0.2518760 (993)\ttotal: 5m 42s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2518759779\n",
      "bestIteration = 993\n",
      "\n",
      "Shrink model to first 994 iterations.\n",
      "\u001b[32m[I 2021-09-22 09:51:54,968]\u001b[0m Trial 11 finished with value: 0.9313624515224748 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08305385358807633, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 11 with value: 0.9313624515224748.\u001b[0m\n",
      "Learning rate set to 0.199658\n",
      "0:\tlearn: 0.4775720\ttest: 0.4774163\tbest: 0.4774163 (0)\ttotal: 549ms\tremaining: 9m 8s\n",
      "999:\tlearn: 0.2512430\ttest: 0.2519199\tbest: 0.2519199 (997)\ttotal: 6m 5s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2519199296\n",
      "bestIteration = 997\n",
      "\n",
      "Shrink model to first 998 iterations.\n",
      "\u001b[32m[I 2021-09-22 09:58:04,013]\u001b[0m Trial 12 finished with value: 0.9313430734088394 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09601973403169853, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 11 with value: 0.9313624515224748.\u001b[0m\n",
      "Learning rate set to 0.199658\n",
      "0:\tlearn: 0.5219112\ttest: 0.5215581\tbest: 0.5215581 (0)\ttotal: 392ms\tremaining: 6m 32s\n",
      "999:\tlearn: 0.2512825\ttest: 0.2518733\tbest: 0.2518733 (993)\ttotal: 5m 29s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2518732857\n",
      "bestIteration = 993\n",
      "\n",
      "Shrink model to first 994 iterations.\n",
      "\u001b[32m[I 2021-09-22 10:03:37,134]\u001b[0m Trial 13 finished with value: 0.931365521106782 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08011736596682306, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 13 with value: 0.931365521106782.\u001b[0m\n",
      "Learning rate set to 0.199658\n",
      "0:\tlearn: 0.5219112\ttest: 0.5215581\tbest: 0.5215581 (0)\ttotal: 460ms\tremaining: 7m 39s\n",
      "999:\tlearn: 0.2513092\ttest: 0.2519000\tbest: 0.2519000 (999)\ttotal: 6m 9s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.251899983\n",
      "bestIteration = 999\n",
      "\n",
      "\u001b[32m[I 2021-09-22 10:09:50,610]\u001b[0m Trial 14 finished with value: 0.9313609574965288 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.07761520334758708, 'depth': 12, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 13 with value: 0.931365521106782.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.199658\n",
      "0:\tlearn: 0.5219112\ttest: 0.5215581\tbest: 0.5215581 (0)\ttotal: 476ms\tremaining: 7m 55s\n",
      "999:\tlearn: 0.2512459\ttest: 0.2518865\tbest: 0.2518863 (990)\ttotal: 6m 39s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2518862935\n",
      "bestIteration = 990\n",
      "\n",
      "Shrink model to first 991 iterations.\n",
      "\u001b[32m[I 2021-09-22 10:16:33,755]\u001b[0m Trial 15 finished with value: 0.9313792672744493 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.0805123693592737, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 15 with value: 0.9313792672744493.\u001b[0m\n",
      "Learning rate set to 0.199658\n",
      "0:\tlearn: 0.5219112\ttest: 0.5215581\tbest: 0.5215581 (0)\ttotal: 436ms\tremaining: 7m 15s\n",
      "999:\tlearn: 0.2514830\ttest: 0.2521242\tbest: 0.2521242 (999)\ttotal: 7m 46s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2521241525\n",
      "bestIteration = 999\n",
      "\n",
      "\u001b[32m[I 2021-09-22 10:24:24,284]\u001b[0m Trial 16 finished with value: 0.9312289533584264 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.07552767562425587, 'depth': 4, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 15 with value: 0.9313792672744493.\u001b[0m\n",
      "Learning rate set to 0.199658\n",
      "0:\tlearn: 0.5219112\ttest: 0.5215581\tbest: 0.5215581 (0)\ttotal: 495ms\tremaining: 8m 14s\n",
      "999:\tlearn: 0.2515622\ttest: 0.2521511\tbest: 0.2521511 (976)\ttotal: 7m 42s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2521511136\n",
      "bestIteration = 976\n",
      "\n",
      "Shrink model to first 977 iterations.\n",
      "\u001b[32m[I 2021-09-22 10:32:11,886]\u001b[0m Trial 17 finished with value: 0.9312296690338104 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.06245837087718495, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 15 with value: 0.9313792672744493.\u001b[0m\n",
      "Learning rate set to 0.199658\n",
      "0:\tlearn: 0.5219112\ttest: 0.5215581\tbest: 0.5215581 (0)\ttotal: 584ms\tremaining: 9m 43s\n",
      "999:\tlearn: 0.2514385\ttest: 0.2520392\tbest: 0.2520392 (999)\ttotal: 6m 46s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2520391947\n",
      "bestIteration = 999\n",
      "\n",
      "\u001b[32m[I 2021-09-22 10:39:04,372]\u001b[0m Trial 18 finished with value: 0.931275395894516 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.06852937352174705, 'depth': 8, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 15 with value: 0.9313792672744493.\u001b[0m\n",
      "Learning rate set to 0.199658\n",
      "0:\tlearn: 0.4775720\ttest: 0.4774163\tbest: 0.4774163 (0)\ttotal: 520ms\tremaining: 8m 39s\n",
      "999:\tlearn: 0.2512596\ttest: 0.2518580\tbest: 0.2518580 (999)\ttotal: 6m 40s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2518579845\n",
      "bestIteration = 999\n",
      "\n",
      "\u001b[32m[I 2021-09-22 10:45:49,355]\u001b[0m Trial 19 finished with value: 0.931371315200297 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08574630229030503, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 15 with value: 0.9313792672744493.\u001b[0m\n",
      "Learning rate set to 0.199658\n",
      "0:\tlearn: 0.4974520\ttest: 0.4974529\tbest: 0.4974529 (0)\ttotal: 1.6s\tremaining: 26m 39s\n",
      "999:\tlearn: 0.2541725\ttest: 0.2545496\tbest: 0.2545496 (999)\ttotal: 6m 46s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2545496318\n",
      "bestIteration = 999\n",
      "\n",
      "\u001b[32m[I 2021-09-22 10:52:43,219]\u001b[0m Trial 20 finished with value: 0.9302392378418167 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08870646704577083, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 9.571217815805316}. Best is trial 15 with value: 0.9313792672744493.\u001b[0m\n",
      "Learning rate set to 0.199658\n",
      "0:\tlearn: 0.4775720\ttest: 0.4774163\tbest: 0.4774163 (0)\ttotal: 559ms\tremaining: 9m 17s\n",
      "999:\tlearn: 0.2513586\ttest: 0.2518818\tbest: 0.2518810 (978)\ttotal: 6m 14s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2518809545\n",
      "bestIteration = 978\n",
      "\n",
      "Shrink model to first 979 iterations.\n",
      "\u001b[32m[I 2021-09-22 10:59:01,965]\u001b[0m Trial 21 finished with value: 0.9313602321720251 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.08330664653229057, 'depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 15 with value: 0.9313792672744493.\u001b[0m\n",
      "Learning rate set to 0.199658\n",
      "0:\tlearn: 0.4775720\ttest: 0.4774163\tbest: 0.4774163 (0)\ttotal: 514ms\tremaining: 8m 33s\n",
      "999:\tlearn: 0.2511950\ttest: 0.2519310\tbest: 0.2519293 (938)\ttotal: 6m 57s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2519292788\n",
      "bestIteration = 938\n",
      "\n",
      "Shrink model to first 939 iterations.\n",
      "\u001b[32m[I 2021-09-22 11:06:03,155]\u001b[0m Trial 22 finished with value: 0.9313501456843725 and parameters: {'objective': 'Logloss', 'colsample_bylevel': 0.09935897603037477, 'depth': 9, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 15 with value: 0.9313792672744493.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'objective': 'Logloss',\n",
       " 'colsample_bylevel': 0.0805123693592737,\n",
       " 'depth': 10,\n",
       " 'boosting_type': 'Ordered',\n",
       " 'bootstrap_type': 'MVS'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cb_fit_params_builder(xvalid, yvalid):\n",
    "    return {\n",
    "        'early_stopping_rounds': 300, \n",
    "        'eval_set': [(xvalid, yvalid)], \n",
    "        'verbose': 1000\n",
    "    }\n",
    "\n",
    "def cb_params_buidler(trial):    \n",
    "    param = {\n",
    "        \"objective\": trial.suggest_categorical(\"objective\", [\"Logloss\", \"CrossEntropy\"]),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 12),\n",
    "        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\n",
    "            \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n",
    "        ),\n",
    "        'random_state': 1\n",
    "    }\n",
    "\n",
    "    if param[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
    "    elif param[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "        param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1)\n",
    "\n",
    "    return param\n",
    "\n",
    "cb_study = optuna.create_study(direction=\"maximize\")\n",
    "cb_study.optimize(Run(CatBoostClassifier, cb_params_buidler, cb_fit_params_builder), \n",
    "                  n_trials=50,\n",
    "                  timeout=60*60*2,\n",
    "                  gc_after_trial=True,\n",
    "                 show_progress_bar=True)\n",
    "\n",
    "cb_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd0f06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cb_fit_params_builder(xvalid, yvalid):\n",
    "    return {\n",
    "        'early_stopping_rounds': 300, \n",
    "        'eval_set': [(xvalid, yvalid)], \n",
    "        'verbose': 1000\n",
    "    }\n",
    "\n",
    "def cb_params_buidler(trial):    \n",
    "    param = {\n",
    "        \"objective\": trial.suggest_categorical(\"objective\", [\"Logloss\", \"CrossEntropy\"]),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 12),\n",
    "        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\n",
    "            \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n",
    "        ),\n",
    "        'random_state': 1\n",
    "    }\n",
    "\n",
    "    if param[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
    "    elif param[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "        param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1)\n",
    "\n",
    "    return param\n",
    "\n",
    "cb_study = optuna.create_study(direction=\"maximize\")\n",
    "cb_study.optimize(Run(CatBoostClassifier, cb_params_buidler, cb_fit_params_builder), \n",
    "                  n_trials=50,\n",
    "                  timeout=60*60*2,\n",
    "                  gc_after_trial=True,\n",
    "                 show_progress_bar=True)\n",
    "\n",
    "cb_study.best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
