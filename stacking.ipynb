{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b38bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import optuna\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import keras\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e4cf7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>REGION</th>\n",
       "      <th>TENURE</th>\n",
       "      <th>MONTANT</th>\n",
       "      <th>FREQUENCE_RECH</th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>ARPU_SEGMENT</th>\n",
       "      <th>FREQUENCE</th>\n",
       "      <th>DATA_VOLUME</th>\n",
       "      <th>ON_NET</th>\n",
       "      <th>...</th>\n",
       "      <th>id_y</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>id_x</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>id_y</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>id_x</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>id_y</th>\n",
       "      <th>pred_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000bfd7d50f01092811bc0c8d7b0d6fe7c3596</td>\n",
       "      <td>FATICK</td>\n",
       "      <td>K &gt; 24 month</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4251.0</td>\n",
       "      <td>1417.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00000bfd7d50f01092811bc0c8d7b0d6fe7c3596</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>00000bfd7d50f01092811bc0c8d7b0d6fe7c3596</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>00000bfd7d50f01092811bc0c8d7b0d6fe7c3596</td>\n",
       "      <td>0.004463</td>\n",
       "      <td>00000bfd7d50f01092811bc0c8d7b0d6fe7c3596</td>\n",
       "      <td>0.008806</td>\n",
       "      <td>00000bfd7d50f01092811bc0c8d7b0d6fe7c3596</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000cb4a5d760de88fecb38e2f71b7bec52e834</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I 18-21 month</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>00000cb4a5d760de88fecb38e2f71b7bec52e834</td>\n",
       "      <td>0.620179</td>\n",
       "      <td>00000cb4a5d760de88fecb38e2f71b7bec52e834</td>\n",
       "      <td>0.627454</td>\n",
       "      <td>00000cb4a5d760de88fecb38e2f71b7bec52e834</td>\n",
       "      <td>0.607547</td>\n",
       "      <td>00000cb4a5d760de88fecb38e2f71b7bec52e834</td>\n",
       "      <td>0.879773</td>\n",
       "      <td>00000cb4a5d760de88fecb38e2f71b7bec52e834</td>\n",
       "      <td>0.632568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001654a9d9f96303d9969d0a4a851714a4bb57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K &gt; 24 month</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00001654a9d9f96303d9969d0a4a851714a4bb57</td>\n",
       "      <td>0.148125</td>\n",
       "      <td>00001654a9d9f96303d9969d0a4a851714a4bb57</td>\n",
       "      <td>0.136944</td>\n",
       "      <td>00001654a9d9f96303d9969d0a4a851714a4bb57</td>\n",
       "      <td>0.132337</td>\n",
       "      <td>00001654a9d9f96303d9969d0a4a851714a4bb57</td>\n",
       "      <td>0.305990</td>\n",
       "      <td>00001654a9d9f96303d9969d0a4a851714a4bb57</td>\n",
       "      <td>0.146315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00001dd6fa45f7ba044bd5d84937be464ce78ac2</td>\n",
       "      <td>DAKAR</td>\n",
       "      <td>K &gt; 24 month</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13502.0</td>\n",
       "      <td>4501.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>43804.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00001dd6fa45f7ba044bd5d84937be464ce78ac2</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>00001dd6fa45f7ba044bd5d84937be464ce78ac2</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>00001dd6fa45f7ba044bd5d84937be464ce78ac2</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>00001dd6fa45f7ba044bd5d84937be464ce78ac2</td>\n",
       "      <td>0.005401</td>\n",
       "      <td>00001dd6fa45f7ba044bd5d84937be464ce78ac2</td>\n",
       "      <td>0.001037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000028d9e13a595abe061f9b58f3d76ab907850f</td>\n",
       "      <td>DAKAR</td>\n",
       "      <td>K &gt; 24 month</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>000028d9e13a595abe061f9b58f3d76ab907850f</td>\n",
       "      <td>0.025337</td>\n",
       "      <td>000028d9e13a595abe061f9b58f3d76ab907850f</td>\n",
       "      <td>0.021932</td>\n",
       "      <td>000028d9e13a595abe061f9b58f3d76ab907850f</td>\n",
       "      <td>0.021137</td>\n",
       "      <td>000028d9e13a595abe061f9b58f3d76ab907850f</td>\n",
       "      <td>0.116135</td>\n",
       "      <td>000028d9e13a595abe061f9b58f3d76ab907850f</td>\n",
       "      <td>0.023210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    user_id  REGION         TENURE  MONTANT  \\\n",
       "0  00000bfd7d50f01092811bc0c8d7b0d6fe7c3596  FATICK   K > 24 month   4250.0   \n",
       "1  00000cb4a5d760de88fecb38e2f71b7bec52e834     NaN  I 18-21 month      NaN   \n",
       "2  00001654a9d9f96303d9969d0a4a851714a4bb57     NaN   K > 24 month   3600.0   \n",
       "3  00001dd6fa45f7ba044bd5d84937be464ce78ac2   DAKAR   K > 24 month  13500.0   \n",
       "4  000028d9e13a595abe061f9b58f3d76ab907850f   DAKAR   K > 24 month   1000.0   \n",
       "\n",
       "   FREQUENCE_RECH  REVENUE  ARPU_SEGMENT  FREQUENCE  DATA_VOLUME  ON_NET  ...  \\\n",
       "0            15.0   4251.0        1417.0       17.0          4.0   388.0  ...   \n",
       "1             NaN      NaN           NaN        NaN          NaN     NaN  ...   \n",
       "2             2.0   1020.0         340.0        2.0          NaN    90.0  ...   \n",
       "3            15.0  13502.0        4501.0       18.0      43804.0    41.0  ...   \n",
       "4             1.0    985.0         328.0        1.0          NaN    39.0  ...   \n",
       "\n",
       "                                       id_y    pred_2  \\\n",
       "0  00000bfd7d50f01092811bc0c8d7b0d6fe7c3596  0.000734   \n",
       "1  00000cb4a5d760de88fecb38e2f71b7bec52e834  0.620179   \n",
       "2  00001654a9d9f96303d9969d0a4a851714a4bb57  0.148125   \n",
       "3  00001dd6fa45f7ba044bd5d84937be464ce78ac2  0.000508   \n",
       "4  000028d9e13a595abe061f9b58f3d76ab907850f  0.025337   \n",
       "\n",
       "                                       id_x    pred_3  \\\n",
       "0  00000bfd7d50f01092811bc0c8d7b0d6fe7c3596  0.000458   \n",
       "1  00000cb4a5d760de88fecb38e2f71b7bec52e834  0.627454   \n",
       "2  00001654a9d9f96303d9969d0a4a851714a4bb57  0.136944   \n",
       "3  00001dd6fa45f7ba044bd5d84937be464ce78ac2  0.000498   \n",
       "4  000028d9e13a595abe061f9b58f3d76ab907850f  0.021932   \n",
       "\n",
       "                                       id_y    pred_4  \\\n",
       "0  00000bfd7d50f01092811bc0c8d7b0d6fe7c3596  0.004463   \n",
       "1  00000cb4a5d760de88fecb38e2f71b7bec52e834  0.607547   \n",
       "2  00001654a9d9f96303d9969d0a4a851714a4bb57  0.132337   \n",
       "3  00001dd6fa45f7ba044bd5d84937be464ce78ac2  0.004372   \n",
       "4  000028d9e13a595abe061f9b58f3d76ab907850f  0.021137   \n",
       "\n",
       "                                       id_x    pred_5  \\\n",
       "0  00000bfd7d50f01092811bc0c8d7b0d6fe7c3596  0.008806   \n",
       "1  00000cb4a5d760de88fecb38e2f71b7bec52e834  0.879773   \n",
       "2  00001654a9d9f96303d9969d0a4a851714a4bb57  0.305990   \n",
       "3  00001dd6fa45f7ba044bd5d84937be464ce78ac2  0.005401   \n",
       "4  000028d9e13a595abe061f9b58f3d76ab907850f  0.116135   \n",
       "\n",
       "                                       id_y    pred_6  \n",
       "0  00000bfd7d50f01092811bc0c8d7b0d6fe7c3596  0.000210  \n",
       "1  00000cb4a5d760de88fecb38e2f71b7bec52e834  0.632568  \n",
       "2  00001654a9d9f96303d9969d0a4a851714a4bb57  0.146315  \n",
       "3  00001dd6fa45f7ba044bd5d84937be464ce78ac2  0.001037  \n",
       "4  000028d9e13a595abe061f9b58f3d76ab907850f  0.023210  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/train_folds.zip\")\n",
    "df_test = pd.read_csv(\"./data/Test.zip\")\n",
    "\n",
    "df1 = pd.read_csv(\"./data/train_pred_1.csv\")\n",
    "df1.columns = [\"id\", \"pred_1\"]\n",
    "df2 = pd.read_csv(\"./data/train_pred_2.csv\")\n",
    "df2.columns = [\"id\", \"pred_2\"]\n",
    "df3 = pd.read_csv(\"./data/train_pred_3.csv\")\n",
    "df3.columns = [\"id\", \"pred_3\"]\n",
    "df4 = pd.read_csv(\"./data/train_pred_4.csv\")\n",
    "df4.columns = [\"id\", \"pred_4\"]\n",
    "df5 = pd.read_csv(\"./data/train_pred_5.csv\")\n",
    "df5.columns = [\"id\", \"pred_5\"]\n",
    "df6 = pd.read_csv(\"./data/train_pred_6.csv\")\n",
    "df6.columns = [\"id\", \"pred_6\"]\n",
    "\n",
    "df_test1 = pd.read_csv(\"./data/test_pred_1.csv\")\n",
    "df_test1.columns = [\"id\", \"pred_1\"]\n",
    "df_test2 = pd.read_csv(\"./data/test_pred_2.csv\")\n",
    "df_test2.columns = [\"id\", \"pred_2\"]\n",
    "df_test3 = pd.read_csv(\"./data/test_pred_3.csv\")\n",
    "df_test3.columns = [\"id\", \"pred_3\"]\n",
    "df_test4 = pd.read_csv(\"./data/test_pred_4.csv\")\n",
    "df_test4.columns = [\"id\", \"pred_4\"]\n",
    "df_test5 = pd.read_csv(\"./data/test_pred_5.csv\")\n",
    "df_test5.columns = [\"id\", \"pred_5\"]\n",
    "df_test6 = pd.read_csv(\"./data/test_pred_6.csv\")\n",
    "df_test6.columns = [\"id\", \"pred_6\"]\n",
    "\n",
    "df = df.merge(df1, left_on=\"user_id\", right_on='id', how=\"left\")\n",
    "df = df.merge(df2, left_on=\"user_id\", right_on='id', how=\"left\")\n",
    "df = df.merge(df3, left_on=\"user_id\", right_on='id', how=\"left\")\n",
    "df = df.merge(df4, left_on=\"user_id\", right_on='id', how=\"left\")\n",
    "df = df.merge(df5, left_on=\"user_id\", right_on='id', how=\"left\")\n",
    "df = df.merge(df6, left_on=\"user_id\", right_on='id', how=\"left\")\n",
    "\n",
    "df_test = df_test.merge(df_test1, left_on=\"user_id\", right_on='id', how=\"left\")\n",
    "df_test = df_test.merge(df_test2, left_on=\"user_id\", right_on='id', how=\"left\")\n",
    "df_test = df_test.merge(df_test3, left_on=\"user_id\", right_on='id', how=\"left\")\n",
    "df_test = df_test.merge(df_test4, left_on=\"user_id\", right_on='id', how=\"left\")\n",
    "df_test = df_test.merge(df_test5, left_on=\"user_id\", right_on='id', how=\"left\")\n",
    "df_test = df_test.merge(df_test6, left_on=\"user_id\", right_on='id', how=\"left\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43c81ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_fit_params_builder(xvalid, yvalid):\n",
    "    return {}\n",
    "\n",
    "def gb_fit_params_builder(xvalid, yvalid):\n",
    "    return {\n",
    "        'early_stopping_rounds': 300, \n",
    "        'eval_set': [(xvalid, yvalid)], \n",
    "        'verbose': 1000\n",
    "    }\n",
    "\n",
    "params = [\n",
    "    (GradientBoostingClassifier, {\n",
    "        'n_estimators': 100,\n",
    "        'random_state': 42, \n",
    "        'verbose': 1,\n",
    "        'max_features': 0.1,\n",
    "    }, \n",
    "     empty_fit_params_builder),\n",
    "    (RandomForestClassifier, {\n",
    "        'max_depth': 10,\n",
    "        'max_features': 'auto',\n",
    "        'class_weight': None,\n",
    "        'n_estimators': 100,\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42,\n",
    "        'verbose': 1,\n",
    "    }, \n",
    "     empty_fit_params_builder),\n",
    "    (XGBClassifier, {\n",
    "        'learning_rate': 0.012279294564643916,\n",
    "        'reg_lambda': 3.5341083287733105e-06,\n",
    "        'reg_alpha': 2.3190508055586554e-05,\n",
    "        'subsample': 0.9271952162018878,\n",
    "        'colsample_bytree': 0.9955235948592415,\n",
    "        'max_depth': 4,\n",
    "        'random_state': 1,\n",
    "        'n_estimators': 7000,\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'gpu_id': 0,\n",
    "        'predictor': \"gpu_predictor\",\n",
    "    }, \n",
    "     gb_fit_params_builder),\n",
    "    (LGBMClassifier, {\n",
    "        'learning_rate': 0.03924735805719372,\n",
    "        'reg_lambda': 2.0139848865528562,\n",
    "        'reg_alpha': 2.380837889033024,\n",
    "        'subsample': 0.6977006896659559,\n",
    "        'colsample_bytree': 0.9408555739613342,\n",
    "        'max_depth': 7,\n",
    "        'random_state': 42,\n",
    "        'n_estimators': 7000,\n",
    "    },\n",
    "     gb_fit_params_builder),\n",
    "    (CatBoostClassifier, {\n",
    "        'objective': 'Logloss',\n",
    "        'colsample_bylevel': 0.0805123693592737,\n",
    "        'depth': 10,\n",
    "        'boosting_type': 'Ordered',\n",
    "        'bootstrap_type': 'MVS',\n",
    "        'random_state': 1,\n",
    "    },\n",
    "     gb_fit_params_builder),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0530a253",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_features = [\"pred_1\", \"pred_2\", \"pred_3\", \"pred_4\", \"pred_5\", \"pred_6\"]\n",
    "df_test = df_test[useful_features]\n",
    "\n",
    "def build_levels(classifier, params, fit_params_buidler, num):\n",
    "    sample_submission = pd.read_csv(\"./data/SampleSubmission.csv\")\n",
    "    \n",
    "    final_test_predictions = []\n",
    "    final_valid_predictions = {}\n",
    "    scores = []\n",
    "    for fold in range(5):\n",
    "        xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
    "        xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
    "        xtest = df_test.copy()\n",
    "\n",
    "        valid_ids = xvalid.user_id.values.tolist()\n",
    "\n",
    "        ytrain = xtrain['CHURN']\n",
    "        yvalid = xvalid['CHURN']\n",
    "\n",
    "        xtrain = xtrain[useful_features]\n",
    "        xvalid = xvalid[useful_features]\n",
    "\n",
    "        model = classifier(**params)\n",
    "        \n",
    "        fit_params = fit_params_buidler(xvalid, yvalid)\n",
    "        model.fit(xtrain, ytrain, **fit_params)\n",
    "        preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "        test_preds = model.predict_proba(xtest)[:, 1]\n",
    "        final_test_predictions.append(test_preds)\n",
    "        final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "        score = roc_auc_score(yvalid, preds_valid)\n",
    "        print(fold, score)\n",
    "        scores.append(score)\n",
    "\n",
    "    print(np.mean(scores), np.std(scores))\n",
    "    final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "    final_valid_predictions.columns = [\"id\", f\"pred_{num}\"]\n",
    "    final_valid_predictions.to_csv(f\"level1_train_pred_{num}.csv\", index=False)\n",
    "\n",
    "    sample_submission[f'pred_{num}'] = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "    sample_submission[['user_id', f'pred_{num}']].to_csv(f\"level1_test_pred_{num}.csv\", index=False)    \n",
    "#     print(sample_submission)\n",
    "#     print(final_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3a04fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4198e5d306e246b6ad6cf7135d009398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8780            2.33m\n",
      "         2           0.8152            2.23m\n",
      "         3           0.7667            2.13m\n",
      "         4           0.7277            2.11m\n",
      "         5           0.6957            2.05m\n",
      "         6           0.6692            2.04m\n",
      "         7           0.6468            2.01m\n",
      "         8           0.6279            2.01m\n",
      "         9           0.6116            1.98m\n",
      "        10           0.5977            1.94m\n",
      "        20           0.5290            1.71m\n",
      "        30           0.5110            1.47m\n",
      "        40           0.5056            1.25m\n",
      "        50           0.5037            1.04m\n",
      "        60           0.5031           49.99s\n",
      "        70           0.5028           37.57s\n",
      "        80           0.5027           24.97s\n",
      "        90           0.5025           12.46s\n",
      "       100           0.5025            0.00s\n",
      "0 0.9312996708217351\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8783            2.25m\n",
      "         2           0.8155            2.17m\n",
      "         3           0.7671            2.10m\n",
      "         4           0.7281            2.08m\n",
      "         5           0.6962            2.03m\n",
      "         6           0.6696            2.02m\n",
      "         7           0.6472            1.98m\n",
      "         8           0.6284            1.97m\n",
      "         9           0.6121            1.94m\n",
      "        10           0.5982            1.90m\n",
      "        20           0.5296            1.70m\n",
      "        30           0.5114            1.48m\n",
      "        40           0.5062            1.26m\n",
      "        50           0.5043            1.06m\n",
      "        60           0.5037           50.48s\n",
      "        70           0.5034           37.78s\n",
      "        80           0.5033           25.15s\n",
      "        90           0.5032           12.60s\n",
      "       100           0.5031            0.00s\n",
      "1 0.931992590348161\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8786            2.29m\n",
      "         2           0.8157            2.23m\n",
      "         3           0.7671            2.14m\n",
      "         4           0.7281            2.13m\n",
      "         5           0.6961            2.08m\n",
      "         6           0.6695            2.06m\n",
      "         7           0.6470            2.02m\n",
      "         8           0.6282            2.02m\n",
      "         9           0.6119            1.99m\n",
      "        10           0.5979            1.95m\n",
      "        20           0.5292            1.73m\n",
      "        30           0.5111            1.50m\n",
      "        40           0.5057            1.27m\n",
      "        50           0.5037            1.06m\n",
      "        60           0.5032           50.35s\n",
      "        70           0.5029           37.76s\n",
      "        80           0.5027           25.20s\n",
      "        90           0.5026           12.57s\n",
      "       100           0.5025            0.00s\n",
      "2 0.9310342194915915\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8785            2.32m\n",
      "         2           0.8157            2.24m\n",
      "         3           0.7672            2.15m\n",
      "         4           0.7282            2.14m\n",
      "         5           0.6963            2.09m\n",
      "         6           0.6697            2.08m\n",
      "         7           0.6473            2.03m\n",
      "         8           0.6284            2.01m\n",
      "         9           0.6121            1.98m\n",
      "        10           0.5982            1.94m\n",
      "        20           0.5295            1.75m\n",
      "        30           0.5115            1.51m\n",
      "        40           0.5059            1.28m\n",
      "        50           0.5042            1.08m\n",
      "        60           0.5036           51.18s\n",
      "        70           0.5033           38.41s\n",
      "        80           0.5032           25.49s\n",
      "        90           0.5031           12.70s\n",
      "       100           0.5030            0.00s\n",
      "3 0.9316451229500886\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8784            2.24m\n",
      "         2           0.8155            2.16m\n",
      "         3           0.7668            2.09m\n",
      "         4           0.7278            2.06m\n",
      "         5           0.6957            2.01m\n",
      "         6           0.6691            2.00m\n",
      "         7           0.6466            1.96m\n",
      "         8           0.6278            1.95m\n",
      "         9           0.6115            1.92m\n",
      "        10           0.5975            1.88m\n",
      "        20           0.5287            1.68m\n",
      "        30           0.5105            1.46m\n",
      "        40           0.5051            1.24m\n",
      "        50           0.5033            1.03m\n",
      "        60           0.5027           49.31s\n",
      "        70           0.5024           37.11s\n",
      "        80           0.5023           24.67s\n",
      "        90           0.5022           12.33s\n",
      "       100           0.5021            0.00s\n",
      "4 0.9304629178774011\n",
      "0.9312869042977955 0.000523312453691928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9314975231809958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.9321665273260387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.9311953615067423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.9318166846519619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   35.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.9306740964525871\n",
      "0.9314700386236652 0.0005128326901867535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:50:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68493\n",
      "[1000]\tvalidation_0-logloss:0.25154\n",
      "[1243]\tvalidation_0-logloss:0.25155\n",
      "0 0.9315228863242917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:50:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68493\n",
      "[1000]\tvalidation_0-logloss:0.25052\n",
      "[1614]\tvalidation_0-logloss:0.25051\n",
      "1 0.9321442135734626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:51:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68493\n",
      "[1000]\tvalidation_0-logloss:0.25154\n",
      "[1025]\tvalidation_0-logloss:0.25154\n",
      "2 0.931176920088021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:51:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68493\n",
      "[1000]\tvalidation_0-logloss:0.25058\n",
      "[1725]\tvalidation_0-logloss:0.25057\n",
      "3 0.9318335231020916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:51:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.68494\n",
      "[1000]\tvalidation_0-logloss:0.25226\n",
      "[1871]\tvalidation_0-logloss:0.25225\n",
      "4 0.9306976967753648\n",
      "0.9314750479726464 0.0005043274030113346\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid_0's binary_logloss: 0.251535\n",
      "0 0.9315172641685638\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[340]\tvalid_0's binary_logloss: 0.250469\n",
      "1 0.9321714247368614\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[202]\tvalid_0's binary_logloss: 0.25158\n",
      "2 0.9311614590070634\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid_0's binary_logloss: 0.250572\n",
      "3 0.9318107979830799\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[216]\tvalid_0's binary_logloss: 0.252422\n",
      "4 0.930708114937625\n",
      "0.9314738121666387 0.0005071424963267435\n",
      "Learning rate set to 0.199658\n",
      "0:\tlearn: 0.4883850\ttest: 0.4883386\tbest: 0.4883386 (0)\ttotal: 621ms\tremaining: 10m 20s\n",
      "999:\tlearn: 0.2511833\ttest: 0.2518201\tbest: 0.2518201 (998)\ttotal: 4m 57s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2518201021\n",
      "bestIteration = 998\n",
      "\n",
      "Shrink model to first 999 iterations.\n",
      "0 0.9313754223560325\n",
      "Learning rate set to 0.199658\n",
      "0:\tlearn: 0.4584974\ttest: 0.4585325\tbest: 0.4585325 (0)\ttotal: 493ms\tremaining: 8m 12s\n",
      "999:\tlearn: 0.2515224\ttest: 0.2507465\tbest: 0.2507465 (998)\ttotal: 4m 56s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2507465075\n",
      "bestIteration = 998\n",
      "\n",
      "Shrink model to first 999 iterations.\n",
      "1 0.9319621615662871\n",
      "Learning rate set to 0.199658\n",
      "0:\tlearn: 0.4817756\ttest: 0.4816294\tbest: 0.4816294 (0)\ttotal: 454ms\tremaining: 7m 33s\n",
      "999:\tlearn: 0.2512364\ttest: 0.2518977\tbest: 0.2518977 (996)\ttotal: 4m 59s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2518976622\n",
      "bestIteration = 996\n",
      "\n",
      "Shrink model to first 997 iterations.\n",
      "2 0.9310391951262753\n",
      "Learning rate set to 0.199658\n",
      "0:\tlearn: 0.5124312\ttest: 0.5121789\tbest: 0.5121789 (0)\ttotal: 388ms\tremaining: 6m 27s\n",
      "999:\tlearn: 0.2515866\ttest: 0.2508997\tbest: 0.2508997 (999)\ttotal: 5m 2s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2508997221\n",
      "bestIteration = 999\n",
      "\n",
      "3 0.931704982543942\n",
      "Learning rate set to 0.199658\n",
      "0:\tlearn: 0.5147878\ttest: 0.5150570\tbest: 0.5150570 (0)\ttotal: 433ms\tremaining: 7m 12s\n",
      "999:\tlearn: 0.2510332\ttest: 0.2527195\tbest: 0.2527188 (962)\ttotal: 5m 6s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2527188085\n",
      "bestIteration = 962\n",
      "\n",
      "Shrink model to first 963 iterations.\n",
      "4 0.930556026986622\n",
      "0.9313275577158319 0.0004951515365701606\n"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(tqdm(params)):\n",
    "    build_levels(p[0], p[1], p[2], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2415c7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:26:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67329\n",
      "[711]\tvalidation_0-logloss:0.25154\n",
      "0 0.9314920060542602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:32:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67332\n",
      "[685]\tvalidation_0-logloss:0.25050\n",
      "1 0.9321122137693799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:38:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67335\n",
      "[613]\tvalidation_0-logloss:0.25153\n",
      "2 0.9311628806751542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:43:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67329\n",
      "[630]\tvalidation_0-logloss:0.25059\n",
      "3 0.9317941847662046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:49:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.67335\n",
      "[689]\tvalidation_0-logloss:0.25223\n",
      "4 0.9306793422042942\n",
      "0.9314481254938587 0.0004970086748043533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp/ipykernel_27632/2224334189.py:48: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  sample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(\"./data/SampleSubmission.csv\")\n",
    "useful_features = [\"pred_1\", \"pred_2\", \"pred_3\", \"pred_4\", \"pred_5\"]\n",
    "df_test = df_test[useful_features]\n",
    "\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "scores = []\n",
    "for fold in range(5):\n",
    "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    xtest = df_test.copy()\n",
    "\n",
    "    valid_ids = xvalid.id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain['CHURN']\n",
    "    yvalid = xvalid['CHURN']\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    \n",
    "\n",
    "    params = {\n",
    "        'random_state': 1, \n",
    "        'booster': 'gbtree',\n",
    "        'n_estimators': 7000,\n",
    "        'learning_rate': 0.03,\n",
    "        'max_depth': 2\n",
    "    }\n",
    "    \n",
    "    model = XGBClassifier(\n",
    "        n_jobs=4,\n",
    "        **params\n",
    "    )\n",
    "    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n",
    "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "    test_preds = model.predict_proba(xtest)[:, 1]\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    score = roc_auc_score(yvalid, preds_valid)\n",
    "    print(fold, score)\n",
    "    scores.append(score)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"id\", \"pred_1\"]\n",
    "final_valid_predictions.to_csv(\"level1_train_pred_1.csv\", index=False)\n",
    "\n",
    "sample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"id\", \"pred_1\"]\n",
    "sample_submission.to_csv(\"level1_test_pred_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1940f432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9293239254699975\n",
      "1 0.9299844859833515\n",
      "2 0.9290454299254474\n",
      "3 0.9298181691816783\n",
      "4 0.928237137661946\n",
      "0.9292818296444842 0.0006213572649891135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp/ipykernel_27632/3169328845.py:36: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  sample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(\"./data/SampleSubmission.csv\")\n",
    "useful_features = [\"pred_1\", \"pred_2\", \"pred_3\", \"pred_4\", \"pred_5\"]\n",
    "df_test = df_test[useful_features]\n",
    "\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "scores = []\n",
    "for fold in range(5):\n",
    "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    xtest = df_test.copy()\n",
    "\n",
    "    valid_ids = xvalid.id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain['CHURN']\n",
    "    yvalid = xvalid['CHURN']\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=500, n_jobs=-1, max_depth=3, random_state=1)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "    test_preds = model.predict_proba(xtest)[:, 1]\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    score = roc_auc_score(yvalid, preds_valid)\n",
    "    print(fold, score)\n",
    "    scores.append(score)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"id\", \"pred_2\"]\n",
    "final_valid_predictions.to_csv(\"level1_train_pred_2.csv\", index=False)\n",
    "\n",
    "sample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"id\", \"pred_2\"]\n",
    "sample_submission.to_csv(\"level1_test_pred_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "302150b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8777           19.13m\n",
      "         2           0.8148           18.63m\n",
      "         3           0.7660           19.08m\n",
      "         4           0.7270           18.72m\n",
      "         5           0.6949           18.41m\n",
      "         6           0.6682           18.37m\n",
      "         7           0.6457           18.53m\n",
      "         8           0.6268           18.65m\n",
      "         9           0.6106           18.81m\n",
      "        10           0.5967           18.64m\n",
      "        20           0.5282           17.92m\n",
      "        30           0.5101           17.73m\n",
      "        40           0.5048           17.29m\n",
      "        50           0.5032           16.69m\n",
      "        60           0.5026           16.22m\n",
      "        70           0.5024           15.83m\n",
      "        80           0.5023           15.36m\n",
      "        90           0.5022           14.93m\n",
      "       100           0.5022           14.61m\n",
      "       200           0.5017           11.15m\n",
      "       300           0.5013            7.77m\n",
      "       400           0.5010            3.90m\n",
      "       500           0.5008            0.00s\n",
      "0 0.9313458458990447\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8779           17.99m\n",
      "         2           0.8151           17.44m\n",
      "         3           0.7664           17.45m\n",
      "         4           0.7274           17.45m\n",
      "         5           0.6954           17.44m\n",
      "         6           0.6687           17.48m\n",
      "         7           0.6462           17.40m\n",
      "         8           0.6272           17.48m\n",
      "         9           0.6110           17.58m\n",
      "        10           0.5971           17.50m\n",
      "        20           0.5287           17.88m\n",
      "        30           0.5106           17.92m\n",
      "        40           0.5053           17.46m\n",
      "        50           0.5037           16.93m\n",
      "        60           0.5031           16.55m\n",
      "        70           0.5029           16.13m\n",
      "        80           0.5028           15.66m\n",
      "        90           0.5027           15.25m\n",
      "       100           0.5027           14.89m\n",
      "       200           0.5022           11.71m\n",
      "       300           0.5019            7.67m\n",
      "       400           0.5016            3.87m\n",
      "       500           0.5013            0.00s\n",
      "1 0.932042708308598\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8782           17.81m\n",
      "         2           0.8152           17.14m\n",
      "         3           0.7664           17.29m\n",
      "         4           0.7274           17.18m\n",
      "         5           0.6953           17.07m\n",
      "         6           0.6685           17.15m\n",
      "         7           0.6460           17.42m\n",
      "         8           0.6270           17.45m\n",
      "         9           0.6107           17.52m\n",
      "        10           0.5969           17.38m\n",
      "        20           0.5282           17.67m\n",
      "        30           0.5100           17.61m\n",
      "        40           0.5049           17.27m\n",
      "        50           0.5032           16.76m\n",
      "        60           0.5026           16.97m\n",
      "        70           0.5024           17.74m\n",
      "        80           0.5022           17.28m\n",
      "        90           0.5022           16.87m\n",
      "       100           0.5021           16.43m\n",
      "       200           0.5016           12.60m\n",
      "       300           0.5013            8.15m\n",
      "       400           0.5010            3.92m\n",
      "       500           0.5007            0.00s\n",
      "2 0.9310842767921428\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8782           17.58m\n",
      "         2           0.8152           17.14m\n",
      "         3           0.7665           16.81m\n",
      "         4           0.7275           16.80m\n",
      "         5           0.6954           16.70m\n",
      "         6           0.6688           16.63m\n",
      "         7           0.6463           16.50m\n",
      "         8           0.6273           16.54m\n",
      "         9           0.6111           16.60m\n",
      "        10           0.5972           16.64m\n",
      "        20           0.5288           16.45m\n",
      "        30           0.5106           18.78m\n",
      "        40           0.5053           19.75m\n",
      "        50           0.5037           19.26m\n",
      "        60           0.5031           18.41m\n",
      "        70           0.5029           17.58m\n",
      "        80           0.5028           16.78m\n",
      "        90           0.5027           16.07m\n",
      "       100           0.5026           15.47m\n",
      "       200           0.5021           11.87m\n",
      "       300           0.5017            7.97m\n",
      "       400           0.5014            3.94m\n",
      "       500           0.5011            0.00s\n",
      "3 0.9317530241850243\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.8781           17.32m\n",
      "         2           0.8151           17.07m\n",
      "         3           0.7662           17.13m\n",
      "         4           0.7271           17.18m\n",
      "         5           0.6950           17.16m\n",
      "         6           0.6683           17.17m\n",
      "         7           0.6457           17.14m\n",
      "         8           0.6266           17.24m\n",
      "         9           0.6104           17.39m\n",
      "        10           0.5965           17.29m\n",
      "        20           0.5279           17.13m\n",
      "        30           0.5097           16.90m\n",
      "        40           0.5044           16.55m\n",
      "        50           0.5028           16.11m\n",
      "        60           0.5022           15.74m\n",
      "        70           0.5020           15.41m\n",
      "        80           0.5019           15.04m\n",
      "        90           0.5018           14.67m\n",
      "       100           0.5018           14.32m\n",
      "       200           0.5013           10.78m\n",
      "       300           0.5009            7.16m\n",
      "       400           0.5007            3.58m\n",
      "       500           0.5004            0.00s\n",
      "4 0.9306300537616707\n",
      "0.931371181789296 0.000495777897724258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp/ipykernel_27632/770111192.py:36: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  sample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(\"./data/SampleSubmission.csv\")\n",
    "useful_features = [\"pred_1\", \"pred_2\", \"pred_3\", \"pred_4\", \"pred_5\"]\n",
    "df_test = df_test[useful_features]\n",
    "\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "scores = []\n",
    "for fold in range(5):\n",
    "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    xtest = df_test.copy()\n",
    "\n",
    "    valid_ids = xvalid.id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain['CHURN']\n",
    "    yvalid = xvalid['CHURN']\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    \n",
    "    model = GradientBoostingClassifier(n_estimators=500, max_depth=3, random_state=10, verbose=1, max_features=0.5)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "    test_preds = model.predict_proba(xtest)[:, 1]\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    score = roc_auc_score(yvalid, preds_valid)\n",
    "    print(fold, score)\n",
    "    scores.append(score)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"id\", \"pred_3\"]\n",
    "final_valid_predictions.to_csv(\"level1_train_pred_3.csv\", index=False)\n",
    "\n",
    "sample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"id\", \"pred_3\"]\n",
    "sample_submission.to_csv(\"level1_test_pred_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc035a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\projects\\zindi-expresso-churn-prediction-challenge\\venv\\lib\\site-packages\\pandas\\core\\frame.py:9186: FutureWarning: Passing 'suffixes' which cause duplicate columns {'id_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  return merge(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>REGION</th>\n",
       "      <th>TENURE</th>\n",
       "      <th>MONTANT</th>\n",
       "      <th>FREQUENCE_RECH</th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>ARPU_SEGMENT</th>\n",
       "      <th>FREQUENCE</th>\n",
       "      <th>DATA_VOLUME</th>\n",
       "      <th>ON_NET</th>\n",
       "      <th>...</th>\n",
       "      <th>id_x</th>\n",
       "      <th>pred_0</th>\n",
       "      <th>id_y</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>id_x</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>id_y</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>id</th>\n",
       "      <th>pred_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000bfd7d50f01092811bc0c8d7b0d6fe7c3596</td>\n",
       "      <td>FATICK</td>\n",
       "      <td>K &gt; 24 month</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4251.0</td>\n",
       "      <td>1417.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00000bfd7d50f01092811bc0c8d7b0d6fe7c3596</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>00000bfd7d50f01092811bc0c8d7b0d6fe7c3596</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>00000bfd7d50f01092811bc0c8d7b0d6fe7c3596</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>00000bfd7d50f01092811bc0c8d7b0d6fe7c3596</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>00000bfd7d50f01092811bc0c8d7b0d6fe7c3596</td>\n",
       "      <td>0.000889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000cb4a5d760de88fecb38e2f71b7bec52e834</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I 18-21 month</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>00000cb4a5d760de88fecb38e2f71b7bec52e834</td>\n",
       "      <td>0.623912</td>\n",
       "      <td>00000cb4a5d760de88fecb38e2f71b7bec52e834</td>\n",
       "      <td>0.618955</td>\n",
       "      <td>00000cb4a5d760de88fecb38e2f71b7bec52e834</td>\n",
       "      <td>0.622513</td>\n",
       "      <td>00000cb4a5d760de88fecb38e2f71b7bec52e834</td>\n",
       "      <td>0.624550</td>\n",
       "      <td>00000cb4a5d760de88fecb38e2f71b7bec52e834</td>\n",
       "      <td>0.664610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001654a9d9f96303d9969d0a4a851714a4bb57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K &gt; 24 month</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00001654a9d9f96303d9969d0a4a851714a4bb57</td>\n",
       "      <td>0.139086</td>\n",
       "      <td>00001654a9d9f96303d9969d0a4a851714a4bb57</td>\n",
       "      <td>0.136379</td>\n",
       "      <td>00001654a9d9f96303d9969d0a4a851714a4bb57</td>\n",
       "      <td>0.139097</td>\n",
       "      <td>00001654a9d9f96303d9969d0a4a851714a4bb57</td>\n",
       "      <td>0.137898</td>\n",
       "      <td>00001654a9d9f96303d9969d0a4a851714a4bb57</td>\n",
       "      <td>0.145545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00001dd6fa45f7ba044bd5d84937be464ce78ac2</td>\n",
       "      <td>DAKAR</td>\n",
       "      <td>K &gt; 24 month</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13502.0</td>\n",
       "      <td>4501.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>43804.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>00001dd6fa45f7ba044bd5d84937be464ce78ac2</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>00001dd6fa45f7ba044bd5d84937be464ce78ac2</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>00001dd6fa45f7ba044bd5d84937be464ce78ac2</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>00001dd6fa45f7ba044bd5d84937be464ce78ac2</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>00001dd6fa45f7ba044bd5d84937be464ce78ac2</td>\n",
       "      <td>0.000566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000028d9e13a595abe061f9b58f3d76ab907850f</td>\n",
       "      <td>DAKAR</td>\n",
       "      <td>K &gt; 24 month</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>000028d9e13a595abe061f9b58f3d76ab907850f</td>\n",
       "      <td>0.019892</td>\n",
       "      <td>000028d9e13a595abe061f9b58f3d76ab907850f</td>\n",
       "      <td>0.022725</td>\n",
       "      <td>000028d9e13a595abe061f9b58f3d76ab907850f</td>\n",
       "      <td>0.023450</td>\n",
       "      <td>000028d9e13a595abe061f9b58f3d76ab907850f</td>\n",
       "      <td>0.025753</td>\n",
       "      <td>000028d9e13a595abe061f9b58f3d76ab907850f</td>\n",
       "      <td>0.020862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    user_id  REGION         TENURE  MONTANT  \\\n",
       "0  00000bfd7d50f01092811bc0c8d7b0d6fe7c3596  FATICK   K > 24 month   4250.0   \n",
       "1  00000cb4a5d760de88fecb38e2f71b7bec52e834     NaN  I 18-21 month      NaN   \n",
       "2  00001654a9d9f96303d9969d0a4a851714a4bb57     NaN   K > 24 month   3600.0   \n",
       "3  00001dd6fa45f7ba044bd5d84937be464ce78ac2   DAKAR   K > 24 month  13500.0   \n",
       "4  000028d9e13a595abe061f9b58f3d76ab907850f   DAKAR   K > 24 month   1000.0   \n",
       "\n",
       "   FREQUENCE_RECH  REVENUE  ARPU_SEGMENT  FREQUENCE  DATA_VOLUME  ON_NET  ...  \\\n",
       "0            15.0   4251.0        1417.0       17.0          4.0   388.0  ...   \n",
       "1             NaN      NaN           NaN        NaN          NaN     NaN  ...   \n",
       "2             2.0   1020.0         340.0        2.0          NaN    90.0  ...   \n",
       "3            15.0  13502.0        4501.0       18.0      43804.0    41.0  ...   \n",
       "4             1.0    985.0         328.0        1.0          NaN    39.0  ...   \n",
       "\n",
       "                                       id_x    pred_0  \\\n",
       "0  00000bfd7d50f01092811bc0c8d7b0d6fe7c3596  0.000979   \n",
       "1  00000cb4a5d760de88fecb38e2f71b7bec52e834  0.623912   \n",
       "2  00001654a9d9f96303d9969d0a4a851714a4bb57  0.139086   \n",
       "3  00001dd6fa45f7ba044bd5d84937be464ce78ac2  0.000941   \n",
       "4  000028d9e13a595abe061f9b58f3d76ab907850f  0.019892   \n",
       "\n",
       "                                       id_y    pred_1  \\\n",
       "0  00000bfd7d50f01092811bc0c8d7b0d6fe7c3596  0.000370   \n",
       "1  00000cb4a5d760de88fecb38e2f71b7bec52e834  0.618955   \n",
       "2  00001654a9d9f96303d9969d0a4a851714a4bb57  0.136379   \n",
       "3  00001dd6fa45f7ba044bd5d84937be464ce78ac2  0.000289   \n",
       "4  000028d9e13a595abe061f9b58f3d76ab907850f  0.022725   \n",
       "\n",
       "                                       id_x    pred_2  \\\n",
       "0  00000bfd7d50f01092811bc0c8d7b0d6fe7c3596  0.000563   \n",
       "1  00000cb4a5d760de88fecb38e2f71b7bec52e834  0.622513   \n",
       "2  00001654a9d9f96303d9969d0a4a851714a4bb57  0.139097   \n",
       "3  00001dd6fa45f7ba044bd5d84937be464ce78ac2  0.000264   \n",
       "4  000028d9e13a595abe061f9b58f3d76ab907850f  0.023450   \n",
       "\n",
       "                                       id_y    pred_3  \\\n",
       "0  00000bfd7d50f01092811bc0c8d7b0d6fe7c3596  0.000519   \n",
       "1  00000cb4a5d760de88fecb38e2f71b7bec52e834  0.624550   \n",
       "2  00001654a9d9f96303d9969d0a4a851714a4bb57  0.137898   \n",
       "3  00001dd6fa45f7ba044bd5d84937be464ce78ac2  0.000191   \n",
       "4  000028d9e13a595abe061f9b58f3d76ab907850f  0.025753   \n",
       "\n",
       "                                         id    pred_4  \n",
       "0  00000bfd7d50f01092811bc0c8d7b0d6fe7c3596  0.000889  \n",
       "1  00000cb4a5d760de88fecb38e2f71b7bec52e834  0.664610  \n",
       "2  00001654a9d9f96303d9969d0a4a851714a4bb57  0.145545  \n",
       "3  00001dd6fa45f7ba044bd5d84937be464ce78ac2  0.000566  \n",
       "4  000028d9e13a595abe061f9b58f3d76ab907850f  0.020862  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/train_folds.zip\")\n",
    "df_test = pd.read_csv(\"./data/Test.zip\")\n",
    "sample_submission = pd.read_csv(\"./data/SampleSubmission.csv\")\n",
    "\n",
    "df0 = pd.read_csv(\"level1_train_pred_0.csv\")\n",
    "df1 = pd.read_csv(\"level1_train_pred_1.csv\")\n",
    "df2 = pd.read_csv(\"level1_train_pred_2.csv\")\n",
    "df3 = pd.read_csv(\"level1_train_pred_3.csv\")\n",
    "df4 = pd.read_csv(\"level1_train_pred_4.csv\")\n",
    "\n",
    "df_test0 = pd.read_csv(\"level1_test_pred_0.csv\")\n",
    "df_test1 = pd.read_csv(\"level1_test_pred_1.csv\")\n",
    "df_test2 = pd.read_csv(\"level1_test_pred_2.csv\")\n",
    "df_test3 = pd.read_csv(\"level1_test_pred_3.csv\")\n",
    "df_test4 = pd.read_csv(\"level1_test_pred_4.csv\")\n",
    "\n",
    "df = df.merge(df0, left_on='user_id', right_on=\"id\", how=\"left\")\n",
    "df = df.merge(df1, left_on='user_id', right_on=\"id\", how=\"left\")\n",
    "df = df.merge(df2, left_on='user_id', right_on=\"id\", how=\"left\")\n",
    "df = df.merge(df3, left_on='user_id', right_on=\"id\", how=\"left\")\n",
    "df = df.merge(df4, left_on='user_id', right_on=\"id\", how=\"left\")\n",
    "\n",
    "df_test = df_test.merge(df_test0, left_on='user_id', right_on=\"user_id\", how=\"left\")\n",
    "df_test = df_test.merge(df_test1, left_on='user_id', right_on=\"user_id\", how=\"left\")\n",
    "df_test = df_test.merge(df_test2, left_on='user_id', right_on=\"user_id\", how=\"left\")\n",
    "df_test = df_test.merge(df_test3, left_on='user_id', right_on=\"user_id\", how=\"left\")\n",
    "df_test = df_test.merge(df_test4, left_on='user_id', right_on=\"user_id\", how=\"left\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44d27191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>REGION</th>\n",
       "      <th>TENURE</th>\n",
       "      <th>MONTANT</th>\n",
       "      <th>FREQUENCE_RECH</th>\n",
       "      <th>REVENUE</th>\n",
       "      <th>ARPU_SEGMENT</th>\n",
       "      <th>FREQUENCE</th>\n",
       "      <th>DATA_VOLUME</th>\n",
       "      <th>ON_NET</th>\n",
       "      <th>...</th>\n",
       "      <th>ZONE2</th>\n",
       "      <th>MRG</th>\n",
       "      <th>REGULARITY</th>\n",
       "      <th>TOP_PACK</th>\n",
       "      <th>FREQ_TOP_PACK</th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001dbe00e56fc4b1c1b65dda63de2a5ece55f9</td>\n",
       "      <td>THIES</td>\n",
       "      <td>K &gt; 24 month</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1667.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>378.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>42</td>\n",
       "      <td>On-net 1000F=10MilF;10d</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.001086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000055d41c8a62052dd426592e8a4a3342bf565d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I 18-21 month</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>41</td>\n",
       "      <td>Data: 100 F=40MB,24H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.068719</td>\n",
       "      <td>0.071787</td>\n",
       "      <td>0.072642</td>\n",
       "      <td>0.071480</td>\n",
       "      <td>0.071362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000081dd3245e6869a4a9c574c7050e7bb84c2c8</td>\n",
       "      <td>DAKAR</td>\n",
       "      <td>K &gt; 24 month</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>57</td>\n",
       "      <td>Data: 100 F=40MB,24H</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000b76d2145d9445d9ff6b65c9ebc4196c89337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K &gt; 24 month</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.401654</td>\n",
       "      <td>0.395942</td>\n",
       "      <td>0.398299</td>\n",
       "      <td>0.397624</td>\n",
       "      <td>0.396494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000bae5480628cf8fe51ad84bcb39772fc79224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K &gt; 24 month</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NO</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.376721</td>\n",
       "      <td>0.374178</td>\n",
       "      <td>0.375060</td>\n",
       "      <td>0.374096</td>\n",
       "      <td>0.378229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    user_id REGION         TENURE  MONTANT  \\\n",
       "0  00001dbe00e56fc4b1c1b65dda63de2a5ece55f9  THIES   K > 24 month   5000.0   \n",
       "1  000055d41c8a62052dd426592e8a4a3342bf565d    NaN  I 18-21 month    300.0   \n",
       "2  000081dd3245e6869a4a9c574c7050e7bb84c2c8  DAKAR   K > 24 month   3300.0   \n",
       "3  0000b76d2145d9445d9ff6b65c9ebc4196c89337    NaN   K > 24 month      NaN   \n",
       "4  0000bae5480628cf8fe51ad84bcb39772fc79224    NaN   K > 24 month      NaN   \n",
       "\n",
       "   FREQUENCE_RECH  REVENUE  ARPU_SEGMENT  FREQUENCE  DATA_VOLUME  ON_NET  ...  \\\n",
       "0             5.0   5000.0        1667.0        5.0          NaN   378.0  ...   \n",
       "1             2.0    326.0         109.0        3.0        397.0     NaN  ...   \n",
       "2            25.0   3400.0        1133.0       26.0       7150.0     0.0  ...   \n",
       "3             NaN      NaN           NaN        NaN          NaN     NaN  ...   \n",
       "4             NaN      NaN           NaN        NaN          NaN     NaN  ...   \n",
       "\n",
       "   ZONE2  MRG  REGULARITY                 TOP_PACK FREQ_TOP_PACK    pred_0  \\\n",
       "0    NaN   NO          42  On-net 1000F=10MilF;10d           5.0  0.001155   \n",
       "1    NaN   NO          41     Data: 100 F=40MB,24H           1.0  0.068719   \n",
       "2    NaN   NO          57     Data: 100 F=40MB,24H          22.0  0.001132   \n",
       "3    NaN   NO           9                      NaN           NaN  0.401654   \n",
       "4    NaN   NO          10                      NaN           NaN  0.376721   \n",
       "\n",
       "     pred_1    pred_2    pred_3    pred_4  \n",
       "0  0.001115  0.001170  0.001086  0.001086  \n",
       "1  0.071787  0.072642  0.071480  0.071362  \n",
       "2  0.000461  0.000259  0.000388  0.000732  \n",
       "3  0.395942  0.398299  0.397624  0.396494  \n",
       "4  0.374178  0.375060  0.374096  0.378229  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8636a403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9314145083291796\n",
      "1 0.9319840853531944\n",
      "2 0.9311070992866594\n",
      "3 0.931637670244932\n",
      "4 0.9306176693234288\n",
      "0.9313522065074787 0.0004656746423203319\n"
     ]
    }
   ],
   "source": [
    "useful_features = [\"pred_0\", \"pred_1\", \"pred_2\", \"pred_3\", 'pred_4']\n",
    "df_test = df_test[useful_features]\n",
    "\n",
    "final_predictions = []\n",
    "scores = []\n",
    "for fold in range(5):\n",
    "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    xtest = df_test.copy()\n",
    "\n",
    "    ytrain = xtrain['CHURN']\n",
    "    yvalid = xvalid['CHURN']\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    model.fit(xtrain, ytrain)\n",
    "    \n",
    "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "    test_preds = model.predict_proba(xtest)[:, 1]\n",
    "    final_predictions.append(test_preds)\n",
    "    score = roc_auc_score(yvalid, preds_valid)\n",
    "    print(fold, score)\n",
    "    scores.append(score)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "# 0 0.931452296769149\n",
    "# 1 0.9320405785857452\n",
    "# 2 0.9311174885821525\n",
    "# 3 0.9316499975730037\n",
    "# 4 0.9306373918079478\n",
    "# 0.9313795506635996 0.0004764174098602453"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9897b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>CHURN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001dbe00e56fc4b1c1b65dda63de2a5ece55f9</td>\n",
       "      <td>0.027271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000055d41c8a62052dd426592e8a4a3342bf565d</td>\n",
       "      <td>0.044138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000081dd3245e6869a4a9c574c7050e7bb84c2c8</td>\n",
       "      <td>0.027071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000b76d2145d9445d9ff6b65c9ebc4196c89337</td>\n",
       "      <td>0.298354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000bae5480628cf8fe51ad84bcb39772fc79224</td>\n",
       "      <td>0.266843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380122</th>\n",
       "      <td>fffe7e03c7eede2ad0a728ee516c4d342dd16107</td>\n",
       "      <td>0.027125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380123</th>\n",
       "      <td>fffec230e6a1aa51ab37d0051ece42de611e71c6</td>\n",
       "      <td>0.859351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380124</th>\n",
       "      <td>ffff0dcc1ab9812bf205b6d76e9d084053cd96f5</td>\n",
       "      <td>0.134142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380125</th>\n",
       "      <td>ffff91ea6a09a0c8ea42bc6ae33df4b5e06283dc</td>\n",
       "      <td>0.057445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380126</th>\n",
       "      <td>ffffb393b346f5348034e6e22be93778d94d4beb</td>\n",
       "      <td>0.028911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380127 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         user_id     CHURN\n",
       "0       00001dbe00e56fc4b1c1b65dda63de2a5ece55f9  0.027271\n",
       "1       000055d41c8a62052dd426592e8a4a3342bf565d  0.044138\n",
       "2       000081dd3245e6869a4a9c574c7050e7bb84c2c8  0.027071\n",
       "3       0000b76d2145d9445d9ff6b65c9ebc4196c89337  0.298354\n",
       "4       0000bae5480628cf8fe51ad84bcb39772fc79224  0.266843\n",
       "...                                          ...       ...\n",
       "380122  fffe7e03c7eede2ad0a728ee516c4d342dd16107  0.027125\n",
       "380123  fffec230e6a1aa51ab37d0051ece42de611e71c6  0.859351\n",
       "380124  ffff0dcc1ab9812bf205b6d76e9d084053cd96f5  0.134142\n",
       "380125  ffff91ea6a09a0c8ea42bc6ae33df4b5e06283dc  0.057445\n",
       "380126  ffffb393b346f5348034e6e22be93778d94d4beb  0.028911\n",
       "\n",
       "[380127 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(\"./data/SampleSubmission.csv\")\n",
    "sample_submission['CHURN'] = np.mean(np.column_stack(final_predictions), axis=1)\n",
    "sample_submission.to_csv(\"./data/submission-stack-3.csv\", index=False)\n",
    "\n",
    "sample_submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
